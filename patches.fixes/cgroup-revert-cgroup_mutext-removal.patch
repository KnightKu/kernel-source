From: Michal Hocko <mhocko@suse.cz>
Subject: cgroup: revert cgroup_mutex removal from idr_remove
Patch-mainline: no, not affected
References: bnc#918644

Cray has reported the following panic:
16:05:59 WARNING: CPU: 0 PID: 30921 at lib/idr.c:527 idr_remove.part.6+0x243/0x250()
16:05:59 idr_remove called for id=2 which is not allocated.
16:05:59 Modules linked in: lmv(O) fld(O) lustre(O) mdc(O) lov(O) fid(O) dvspn(PO) dvsof(PO) dvsutil(PO) dvsipc(PO) dvsipc_lnet(PO) dvsproc(PO) nic_compat(O) cmsr(O) xpmem(O) osc(O) mgc(O) kgnilnd(O) ptlrpc(O) obdclass(O) lnet(O) sha1_generic libcfs(O) x86_pkg_temp_thermal pcie_link_bw_monitor(O) ib_core(O) kdreg(O) gpcd_ari(O) ipogif_ari(O) kgni_ari(O) hwerr(PO) rca(O) heartbeat(O) simplex(PO) hss_os(PO) ghal_ari(O) freemem(O) craytrace(O)
16:05:59 CPU: 0 PID: 30921 Comm: kworker/0:2 Tainted: P        W  O  3.12.28-4.6_1.0000.8607-cray_ari_c #1
16:05:59 Hardware name: Cray Inc. Cascade/Cascade, BIOS 4.6.5 06/19/2014
16:05:59 Workqueue: cgroup_destroy css_free_work_fn
16:05:59 0000000000000009 ffff8807aab5bc70 ffffffff8147c3ac ffff8807aab5bcb8
16:05:59 ffff8807aab5bca8 ffffffff81044bed ffff8807aab5bd20 ffff88080008b278
16:05:59 ffff88102d6d4238 ffff881000cbbe40 ffff88080008b278 ffff8807aab5bd08
16:05:59 Call Trace:
16:05:59 [<ffffffff81005e11>] try_stack_unwind+0x191/0x1a0
16:05:59 [<ffffffff810046cb>] dump_trace+0x8b/0x350
16:05:59 [<ffffffff81005e6d>] show_trace_log_lvl+0x4d/0x60
16:05:59 [<ffffffff81004a24>] show_stack_log_lvl+0x94/0x180
16:05:59 [<ffffffff81005ec5>] show_stack+0x25/0x50
16:05:59 [<ffffffff8147c3ac>] dump_stack+0x45/0x56
16:05:59 [<ffffffff81044bed>] warn_slowpath_common+0x7d/0xc0
16:05:59 [<ffffffff81044c7c>] warn_slowpath_fmt+0x4c/0x50
16:05:59 [<ffffffff812539a3>] idr_remove.part.6+0x243/0x250
16:05:59 [<ffffffff812539bd>] idr_remove+0xd/0x10
16:05:59 [<ffffffff810c1541>] cgroup_diput+0xd1/0x120
16:05:59 [<ffffffff8118ea94>] __dentry_kill+0x124/0x1f0
16:05:59 [<ffffffff8118ec05>] dput+0xa5/0x170
16:05:59 [<ffffffff810c20ae>] css_free_work_fn+0x4e/0x80
16:05:59 [<ffffffff8106041b>] process_one_work+0x16b/0x3f0
16:05:59 [<ffffffff810610cd>] worker_thread+0x12d/0x390
16:05:59 [<ffffffff81067620>] kthread+0xc0/0xd0
16:05:59 [<ffffffff814895ac>] ret_from_fork+0x7c/0xb0
16:05:59 ---[ end trace 0e9fc2eaadb063bd ]---
16:06:19 ------------[ cut here ]------------
16:06:19 kernel BUG at mm/slab.c:3332!
16:06:19 invalid opcode: 0000 [#1] SMP 
16:06:19 Modules linked in: lmv(O) fld(O) lustre(O) mdc(O) lov(O) fid(O) dvspn(PO) dvsof(PO) dvsutil(PO) dvsipc(PO) dvsipc_lnet(PO) dvsproc(PO) nic_compat(O) cmsr(O) xpmem(O) osc(O) mgc(O) kgnilnd(O) ptlrpc(O) obdclass(O) lnet(O) sha1_generic libcfs(O) x86_pkg_temp_thermal pcie_link_bw_monitor(O) ib_core(O) kdreg(O) gpcd_ari(O) ipogif_ari(O) kgni_ari(O) hwerr(PO) rca(O) heartbeat(O) simplex(PO) hss_os(PO) ghal_ari(O) freemem(O) craytrace(O)
16:06:19 CPU: 13 PID: 10791 Comm: apinit Tainted: P        W  O  3.12.28-4.6_1.0000.8607-cray_ari_c #1
16:06:19 Hardware name: Cray Inc. Cascade/Cascade, BIOS 4.6.5 06/19/2014
16:06:19 task: ffff8808300e4200 ti: ffff880830820000 task.ti: ffff880830820000
16:06:19 RIP: 0010:[<ffffffff8116670f>]  [<ffffffff8116670f>] kmem_cache_alloc+0x3ef/0x490
16:06:19 RSP: 0018:ffff880830821cf0  EFLAGS: 00010046
16:06:19 RAX: ffff88102bda4180 RBX: ffff88102c52a080 RCX: ffff881020001940
16:06:19 RDX: ffff88102bda4180 RSI: ffff881020001948 RDI: 0000000000000003
16:06:19 RBP: ffff880830821d58 R08: ffff88102b28e680 R09: ffff881020001968
16:06:19 R10: ffff881020001958 R11: 0000000000000007 R12: 00000000000082d0
16:06:19 R13: 0000000000000202 R14: ffff880820009880 R15: 0000000000000005
16:06:19 FS:  00007ffff7fcf780(0000) GS:ffff88107f8c0000(0000) knlGS:0000000000000000
16:06:19 CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
16:06:19 CR2: 000000000066500f CR3: 000000102d960000 CR4: 00000000001407e0
16:06:19 Stack:
16:06:19 ffff881030be8bc0 ffff88082b1fc200 ffff880830821d30 ffffffff81071868
16:06:19 ffff881020001940 ffff88102b28e680 000000010000000d ffff8808000082d0
16:06:19 00000000000000d0 0000000000000000 0000000000000000 ffff880830821de0
16:06:19 Call Trace:
16:06:19 [<ffffffff8125367e>] idr_layer_alloc+0x2e/0x90
16:06:19 [<ffffffff81253f3e>] idr_get_empty_slot+0x3ae/0x3d0
16:06:19 [<ffffffff812540fe>] idr_alloc+0xae/0xe0
16:06:19 [<ffffffff810c4773>] cgroup_mkdir+0xf3/0x680
16:06:19 [<ffffffff81184689>] vfs_mkdir+0x99/0x140
16:06:19 [<ffffffff81189770>] SyS_mkdirat+0x60/0xc0
16:06:19 [<ffffffff811897e9>] SyS_mkdir+0x19/0x20
16:06:19 [<ffffffff81489652>] system_call_fastpath+0x16/0x1b
16:06:19 [<00007ffff6654227>] 0x7ffff6654226

The issue has been introduced by patch-3.12.15-16 which has a backport for
0ab02ca8f887 (cgroup: protect modifications to cgroup_idr with cgroup_mutex).
The stable-3.12 doesn't contain cgroup_mutex around idr_remove because it
wasn't really needed for 3.12 based tree (see
https://lkml.org/lkml/2014/2/11/140). SLE12, however contains
patches.suse/memcg-convert-to-use-cgroup-id.patch and its follow up fix
patches.suse/cgroup-don-t-recycle-cgroup-id-until-all-csses-have-.patch which
are from 3.13 kernel and the later one calls idr_remove from cgroup_diput so
we really need to protect from parallel idr manipulation.

This patch adds the missing lock back. Thanks to Cray developers for their
analysis and Li Zefan (from Huawei) to point out the cgroup_diput path which I
haven't noticed.

We do not want to take cgroup_mutex around deactivate_super(sb) though because
that could lead to a deadlock if we are racing with unmount.

Signed-off-by: Michal Hocko <mhocko@suse.cz>

---
 kernel/cgroup.c |    2 ++
 1 file changed, 2 insertions(+)

--- a/kernel/cgroup.c
+++ b/kernel/cgroup.c
@@ -934,8 +934,10 @@ static void cgroup_diput(struct dentry *
 		 * per-subsystem and moved to css->id so that lookups are
 		 * successful until the target css is released.
 		 */
+		mutex_lock(&cgroup_mutex);
 		idr_remove(&cgrp->root->cgroup_idr, cgrp->id);
 		cgrp->id = -1;
+		mutex_unlock(&cgroup_mutex);
 
 		call_rcu(&cgrp->rcu_head, cgroup_free_rcu);
 	} else {
