From: NeilBrown <neilb@suse.com>
Subject: SUNRPC: restore fair scheduling to priority queues.
References: bsc#955308
Patch-mainline: Not yet, will submit shortly.

Commit: c05eecf63610 ("SUNRPC: Don't allow low priority tasks to pre-empt higher priority ones")

Removed the 'fair scheduling' feature from SUNRPC priority queues.
This feature caused problems for some queues (send queue and session slot queue)
but was still needed for others, particularly the tcp slot queue.

Without fairness, reads (priority 1) could starve background writes (priority 0)
so a streaming read would cause writeback to block indefinitely.

This patch conditionally restored fair scheduling.  It is now the default
unless rpc_sleep_on_priority() is called directly.  Then the queues switches
to strict priority observance.
As that function is called for both the sendqueue and the session slot queue
and not for any others, this has exactly the desired effect.

The "count" field that was removed by the previous patch is restored.
A value for '255' means 'strict priority queuing, no fair queuing".
Any other value is a could of owners to be processed before switching
to a different priority level, just like before.

Signed-off-by: NeilBrown <neilb@suse.com>

---
 net/sunrpc/sched.c |   12 +++++++++---
 1 file changed, 9 insertions(+), 3 deletions(-)

--- a/net/sunrpc/sched.c
+++ b/net/sunrpc/sched.c
@@ -114,6 +114,8 @@ static void rpc_set_waitqueue_priority(s
 		rpc_rotate_queue_owner(queue);
 		queue->priority = priority;
 	}
+	if (queue->count != 255)
+		queue->count = 1 << (priority * 2);
 }
 
 static void rpc_set_waitqueue_owner(struct rpc_wait_queue *queue, pid_t pid)
@@ -141,8 +143,10 @@ static void __rpc_add_wait_queue_priorit
 	INIT_LIST_HEAD(&task->u.tk_wait.links);
 	if (unlikely(queue_priority > queue->maxpriority))
 		queue_priority = queue->maxpriority;
-	if (queue_priority > queue->priority)
-		rpc_set_waitqueue_priority(queue, queue_priority);
+	if (queue->count == 255) {
+		if (queue_priority > queue->priority)
+			rpc_set_waitqueue_priority(queue, queue_priority);
+	}
 	q = &queue->tasks[queue_priority];
 	list_for_each_entry(t, q, u.tk_wait.list) {
 		if (t->tk_owner == task->tk_owner) {
@@ -381,6 +385,7 @@ void rpc_sleep_on_priority(struct rpc_wa
 	 * Protect the queue operations.
 	 */
 	spin_lock_bh(&q->lock);
+	q->count = 255;
 	__rpc_sleep_on_priority(q, task, action, priority - RPC_PRIORITY_LOW);
 	spin_unlock_bh(&q->lock);
 }
@@ -469,7 +474,8 @@ static struct rpc_task *__rpc_find_next_
 		/*
 		 * Check if we need to switch queues.
 		 */
-		goto new_owner;
+		if (queue->count == 255 || --queue->count)
+			goto new_owner;
 	}
 
 	/*
