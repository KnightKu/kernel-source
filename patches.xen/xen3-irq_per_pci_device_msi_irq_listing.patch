From: Neil Horman <nhorman@tuxdriver.com>
Subject: PCI/sysfs: add per pci device msi[x] irq listing (v5)
References: bnc#748340
Patch-mainline: Never, SUSE-Xen specific

Signed-off-by: Thomas Renninger <trenn@suse.de>

This patch adds a per-pci-device subdirectory in sysfs called:
/sys/bus/pci/devices/<device>/msi_irqs

This sub-directory exports the set of msi vectors allocated by a given
pci device, by creating a numbered sub-directory for each vector beneath
msi_irqs.  For each vector various attributes can be exported.
Currently the only attribute is called mode, which tracks the
operational mode of that vector (msi vs. msix)

Acked-by: Greg Kroah-Hartman <gregkh@suse.de>
Signed-off-by: Jesse Barnes <jbarnes@virtuousgeek.org>

Automatically created from "patches.fixes/irq_per_pci_device_msi_irq_listing.patch" by xen-port-patches.py

--- a/drivers/pci/msi-xen.c
+++ b/drivers/pci/msi-xen.c
@@ -37,18 +37,21 @@ static int pci_seg_supported = 1;
 static LIST_HEAD(msi_dev_head);
 DEFINE_SPINLOCK(msi_dev_lock);
 
+struct msi_pirq_entry {
+	struct list_head list;
+	int pirq;
+	int entry_nr;
+	struct msi_dev_list *dev_entry;
+	struct kobject kobj;
+};
+
 struct msi_dev_list {
 	struct pci_dev *dev;
-	struct list_head list;
 	spinlock_t pirq_list_lock;
 	/* Store default pre-assigned irq */
 	unsigned int default_irq;
-};
-
-struct msi_pirq_entry {
-	struct list_head list;
-	int pirq;
-	int entry_nr;
+	domid_t owner;
+	struct msi_pirq_entry e;
 };
 
 /* Arch hooks */
@@ -88,6 +91,21 @@ static void msix_set_enable(struct pci_d
 	}
 }
 
+static int (*get_owner)(struct pci_dev *dev);
+
+static domid_t msi_get_dev_owner(struct pci_dev *dev)
+{
+	int owner;
+
+	if (is_initial_xendomain()
+	    && get_owner && (owner = get_owner(dev)) >= 0) {
+		dev_info(&dev->dev, "get owner: %u\n", owner);
+		return owner;
+	}
+
+	return DOMID_SELF;
+}
+
 static struct msi_dev_list *get_msi_dev_pirq_list(struct pci_dev *dev)
 {
 	struct msi_dev_list *msi_dev_list, *ret = NULL;
@@ -95,12 +113,14 @@ static struct msi_dev_list *get_msi_dev_
 
 	spin_lock_irqsave(&msi_dev_lock, flags);
 
-	list_for_each_entry(msi_dev_list, &msi_dev_head, list)
+	list_for_each_entry(msi_dev_list, &msi_dev_head, e.list)
 		if ( msi_dev_list->dev == dev )
 			ret = msi_dev_list;
 
 	if ( ret ) {
 		spin_unlock_irqrestore(&msi_dev_lock, flags);
+		if (ret->owner == DOMID_IO)
+			ret->owner = msi_get_dev_owner(dev);
 		return ret;
 	}
 
@@ -115,7 +135,10 @@ static struct msi_dev_list *get_msi_dev_
 
 	ret->dev = dev;
 	spin_lock_init(&ret->pirq_list_lock);
-	list_add_tail(&ret->list, &msi_dev_head);
+	ret->owner = msi_get_dev_owner(dev);
+	ret->e.entry_nr = -1;
+	ret->e.dev_entry = ret;
+	list_add_tail(&ret->e.list, &msi_dev_head);
 	spin_unlock_irqrestore(&msi_dev_lock, flags);
 	return ret;
 }
@@ -130,6 +153,8 @@ static int attach_pirq_entry(int pirq, i
 		return -ENOMEM;
 	entry->pirq = pirq;
 	entry->entry_nr = entry_nr;
+	entry->dev_entry = msi_dev_entry;
+	memset(&entry->kobj, 0, sizeof(entry->kobj));
 	spin_lock_irqsave(&msi_dev_entry->pirq_list_lock, flags);
 	list_add_tail(&entry->list, &msi_dev_entry->dev->msi_list);
 	spin_unlock_irqrestore(&msi_dev_entry->pirq_list_lock, flags);
@@ -153,11 +178,10 @@ static void detach_pirq_entry(int entry_
 	}
 }
 
+#ifdef CONFIG_XEN_PRIVILEGED_GUEST
 /*
  * pciback will provide device's owner
  */
-static int (*get_owner)(struct pci_dev *dev);
-
 int register_msi_get_owner(int (*func)(struct pci_dev *dev))
 {
 	if (get_owner) {
@@ -177,39 +201,41 @@ int unregister_msi_get_owner(int (*func)
 	return 0;
 }
 EXPORT_SYMBOL(unregister_msi_get_owner);
+#endif
 
-static int msi_get_dev_owner(struct pci_dev *dev)
+static int msi_unmap_pirq(struct pci_dev *dev, int pirq, domid_t owner,
+			  struct kobject *kobj)
 {
-	int owner;
+	if (is_initial_xendomain()) {
+		struct physdev_unmap_pirq unmap;
+		int rc;
 
-	BUG_ON(!is_initial_xendomain());
-	if (get_owner && (owner = get_owner(dev)) >= 0) {
-		dev_info(&dev->dev, "get owner: %x \n", owner);
-		return owner;
-	}
+		unmap.domid = owner;
+		/* See comments in msi_map_vector, input parameter pirq means
+		 * irq number only if the device belongs to dom0 itself.
+		 */
+		unmap.pirq = (unmap.domid != DOMID_SELF)
+			? pirq : evtchn_get_xen_pirq(pirq);
 
-	return DOMID_SELF;
-}
+		if ((rc = HYPERVISOR_physdev_op(PHYSDEVOP_unmap_pirq, &unmap)))
+			dev_warn(&dev->dev, "unmap irq %d failed\n", pirq);
 
-static int msi_unmap_pirq(struct pci_dev *dev, int pirq)
-{
-	struct physdev_unmap_pirq unmap;
-	int rc;
+		if (rc < 0)
+			return rc;
+	} else
+		owner = DOMID_SELF;
 
-	unmap.domid = msi_get_dev_owner(dev);
-	/* See comments in msi_map_vector, input parameter pirq means
-	 * irq number only if the device belongs to dom0 itself.
+	/*
+	 * Its possible that we get into this path when populate_msi_sysfs()
+	 * fails, which means the entries were not registered with sysfs.
+	 * In that case don't unregister them.
 	 */
-	unmap.pirq = (unmap.domid != DOMID_SELF)
-		? pirq : evtchn_get_xen_pirq(pirq);
-
-	if ((rc = HYPERVISOR_physdev_op(PHYSDEVOP_unmap_pirq, &unmap)))
-		dev_warn(&dev->dev, "unmap irq %d failed\n", pirq);
-
-	if (rc < 0)
-		return rc;
+	if (kobj->parent) {
+		kobject_del(kobj);
+		kobject_put(kobj);
+	}
 
-	if (unmap.domid == DOMID_SELF)
+	if (owner == DOMID_SELF)
 		evtchn_map_pirq(pirq, 0);
 
 	return 0;
@@ -236,13 +262,11 @@ static u64 find_table_base(struct pci_de
 /*
  * Protected by msi_lock
  */
-static int msi_map_vector(struct pci_dev *dev, int entry_nr, u64 table_base)
+static int msi_map_vector(struct pci_dev *dev, int entry_nr, u64 table_base,
+			  domid_t domid)
 {
 	struct physdev_map_pirq map_irq;
 	int rc = -EINVAL;
-	domid_t domid = DOMID_SELF;
-
-	domid = msi_get_dev_owner(dev);
 
 	map_irq.domid = domid;
 	map_irq.type = MAP_PIRQ_TYPE_MSI_SEG;
@@ -341,6 +365,142 @@ void pci_restore_msi_state(struct pci_de
 }
 EXPORT_SYMBOL_GPL(pci_restore_msi_state);
 
+
+#define to_msi_attr(obj) container_of(obj, struct msi_attribute, attr)
+#define to_pirq_entry(obj) container_of(obj, struct msi_pirq_entry, kobj)
+
+struct msi_attribute {
+	struct attribute        attr;
+	ssize_t (*show)(struct msi_pirq_entry *, struct msi_attribute *,
+			char *buf);
+	ssize_t (*store)(struct msi_pirq_entry *, struct msi_attribute *,
+			 const char *buf, size_t count);
+};
+
+static ssize_t show_msi_mode(struct msi_pirq_entry *entry,
+			     struct msi_attribute *attr, char *buf)
+{
+	return sprintf(buf, "%s\n", entry->entry_nr >= 0 ? "msix" : "msi");
+}
+
+static ssize_t show_xen_irq(struct msi_pirq_entry *entry,
+			    struct msi_attribute *attr, char *buf)
+{
+	return sprintf(buf, "%d\n", entry->dev_entry->owner == DOMID_SELF
+				    ? evtchn_get_xen_pirq(entry->pirq)
+				    : entry->pirq);
+}
+
+static ssize_t msi_irq_attr_show(struct kobject *kobj,
+				 struct attribute *attr, char *buf)
+{
+	struct msi_attribute *attribute = to_msi_attr(attr);
+	struct msi_pirq_entry *entry = to_pirq_entry(kobj);
+
+	if (!attribute->show)
+		return -EIO;
+
+	return attribute->show(entry, attribute, buf);
+}
+
+static const struct sysfs_ops msi_irq_sysfs_ops = {
+	.show = msi_irq_attr_show,
+};
+
+static struct msi_attribute mode_attribute =
+	__ATTR(mode, S_IRUGO, show_msi_mode, NULL);
+
+static struct msi_attribute xen_irq_attribute =
+	__ATTR(xen_irq, S_IRUGO, show_xen_irq, NULL);
+
+static struct attribute *msi_irq_default_attrs[] = {
+	&mode_attribute.attr,
+	&xen_irq_attribute.attr,
+	NULL
+};
+
+static struct attribute *msi_pirq_default_attrs[] = {
+	&mode_attribute.attr,
+	NULL
+};
+
+static void msi_kobj_release(struct kobject *kobj)
+{
+	struct msi_dev_list *entry = to_pirq_entry(kobj)->dev_entry;
+
+	pci_dev_put(entry->dev);
+}
+
+static struct kobj_type msi_irq_ktype = {
+	.release = msi_kobj_release,
+	.sysfs_ops = &msi_irq_sysfs_ops,
+	.default_attrs = msi_irq_default_attrs,
+};
+
+static struct kobj_type msi_pirq_ktype = {
+	.release = msi_kobj_release,
+	.sysfs_ops = &msi_irq_sysfs_ops,
+	.default_attrs = msi_pirq_default_attrs,
+};
+
+static int populate_msi_sysfs(struct pci_dev *pdev)
+{
+	struct msi_dev_list *dev_entry = get_msi_dev_pirq_list(pdev);
+	domid_t owner = dev_entry->owner;
+	struct msi_pirq_entry *pirq_entry;
+	struct kobject *kobj;
+	int ret;
+	int count = 0;
+
+	pdev->msi_kset = kset_create_and_add("msi_irqs", NULL, &pdev->dev.kobj);
+	if (!pdev->msi_kset)
+		return -ENOMEM;
+
+	if (pdev->msi_enabled) {
+		kobj = &dev_entry->e.kobj;
+		kobj->kset = pdev->msi_kset;
+		pci_dev_get(pdev);
+		if (owner == DOMID_SELF)
+			ret = kobject_init_and_add(kobj, &msi_irq_ktype, NULL,
+						   "%u", pdev->irq);
+		else
+			ret = kobject_init_and_add(kobj, &msi_pirq_ktype, NULL,
+						   "xen-%u", pdev->irq);
+		if (ret)
+			pci_dev_put(pdev);
+		return ret;
+	}
+
+	list_for_each_entry(pirq_entry, &pdev->msi_list, list) {
+		kobj = &pirq_entry->kobj;
+		kobj->kset = pdev->msi_kset;
+		pci_dev_get(pdev);
+		if (owner == DOMID_SELF)
+			ret = kobject_init_and_add(kobj, &msi_irq_ktype, NULL,
+						   "%u", pirq_entry->pirq);
+		else
+			ret = kobject_init_and_add(kobj, &msi_pirq_ktype, NULL,
+						   "xen-%u", pirq_entry->pirq);
+		if (ret)
+			goto out_unroll;
+
+		count++;
+	}
+
+	return 0;
+
+out_unroll:
+	pci_dev_put(pdev);
+	list_for_each_entry(pirq_entry, &pdev->msi_list, list) {
+		if (!count)
+			break;
+		kobject_del(&pirq_entry->kobj);
+		kobject_put(&pirq_entry->kobj);
+		count--;
+	}
+	return ret;
+}
+
 /**
  * msi_capability_init - configure device's MSI capability structure
  * @dev: pointer to the pci_dev data structure of MSI device function
@@ -354,12 +514,13 @@ EXPORT_SYMBOL_GPL(pci_restore_msi_state)
  */
 static int msi_capability_init(struct pci_dev *dev, int nvec)
 {
+	struct msi_dev_list *dev_entry = get_msi_dev_pirq_list(dev);
 	int pos, pirq;
 
 	pos = pci_find_capability(dev, PCI_CAP_ID_MSI);
 	msi_set_enable(dev, pos, 0);	/* Disable MSI during set up */
 
-	pirq = msi_map_vector(dev, 0, 0);
+	pirq = msi_map_vector(dev, 0, 0, dev_entry->owner);
 	if (pirq < 0)
 		return -EBUSY;
 
@@ -368,7 +529,8 @@ static int msi_capability_init(struct pc
 	msi_set_enable(dev, pos, 1);
 	dev->msi_enabled = 1;
 
-	dev->irq = pirq;
+	dev->irq = dev_entry->e.pirq = pirq;
+	populate_msi_sysfs(dev);
 	return 0;
 }
 
@@ -427,7 +589,8 @@ static int msix_capability_init(struct p
 		}
 		if (mapped)
 			continue;
-		pirq = msi_map_vector(dev, entries[i].entry, table_base);
+		pirq = msi_map_vector(dev, entries[i].entry, table_base,
+				      msi_dev_entry->owner);
 		if (pirq < 0)
 			break;
 		attach_pirq_entry(pirq, entries[i].entry, msi_dev_entry);
@@ -437,7 +600,12 @@ static int msix_capability_init(struct p
 	if (i != nvec) {
 		int avail = i - 1;
 		for (j = --i; j >= 0; j--) {
-			msi_unmap_pirq(dev, entries[j].vector);
+			list_for_each_entry(pirq_entry, &dev->msi_list, list)
+				if (pirq_entry->entry_nr == entries[i].entry)
+					break;
+			msi_unmap_pirq(dev, entries[j].vector,
+				       msi_dev_entry->owner,
+				       &pirq_entry->kobj);
 			detach_pirq_entry(entries[j].entry, msi_dev_entry);
 			entries[j].vector = 0;
 		}
@@ -452,6 +620,7 @@ static int msix_capability_init(struct p
 	/* Set MSI-X enabled bits and unmask the function */
 	pci_intx_for_msi(dev, 0);
 	dev->msix_enabled = 1;
+	populate_msi_sysfs(dev);
 
 	control &= ~PCI_MSIX_FLAGS_MASKALL;
 	pci_write_config_word(dev, pos + PCI_MSIX_FLAGS, control);
@@ -550,7 +719,7 @@ int pci_enable_msi_block(struct pci_dev
 		dev->irq = evtchn_map_pirq(-1, dev->irq);
 		dev->msi_enabled = 1;
 		msi_dev_entry->default_irq = temp;
-
+		populate_msi_sysfs(dev);
 		return ret;
 #else
 		return -EOPNOTSUPP;
@@ -582,31 +751,35 @@ void pci_msi_shutdown(struct pci_dev *de
 	if (!pci_msi_enable || !dev || !dev->msi_enabled)
 		return;
 
-	if (!is_initial_xendomain()) {
+	if (!is_initial_xendomain())
 #ifdef CONFIG_XEN_PCIDEV_FRONTEND
-		evtchn_map_pirq(dev->irq, 0);
 		pci_frontend_disable_msi(dev);
-		dev->irq = msi_dev_entry->default_irq;
-		dev->msi_enabled = 0;
-#endif
+#else
 		return;
-	}
+#endif
 
 	pirq = dev->irq;
 	/* Restore dev->irq to its default pin-assertion vector */
 	dev->irq = msi_dev_entry->default_irq;
-	msi_unmap_pirq(dev, pirq);
+	msi_unmap_pirq(dev, pirq, msi_dev_entry->owner,
+		       &msi_dev_entry->e.kobj);
+	msi_dev_entry->owner = DOMID_IO;
+	memset(&msi_dev_entry->e.kobj, 0, sizeof(msi_dev_entry->e.kobj));
 
 	/* Disable MSI mode */
-	pos = pci_find_capability(dev, PCI_CAP_ID_MSI);
-	msi_set_enable(dev, pos, 0);
-	pci_intx_for_msi(dev, 1);
+	if (is_initial_xendomain()) {
+		pos = pci_find_capability(dev, PCI_CAP_ID_MSI);
+		msi_set_enable(dev, pos, 0);
+		pci_intx_for_msi(dev, 1);
+	}
 	dev->msi_enabled = 0;
 }
 
 void pci_disable_msi(struct pci_dev *dev)
 {
 	pci_msi_shutdown(dev);
+	kset_unregister(dev->msi_kset);
+	dev->msi_kset = NULL;
 }
 EXPORT_SYMBOL(pci_disable_msi);
 
@@ -684,6 +857,7 @@ int pci_enable_msix(struct pci_dev *dev,
 			attach_pirq_entry(irq, entries[i].entry, msi_dev_entry);
 			entries[i].vector = irq;
 		}
+		populate_msi_sysfs(dev);
 		return 0;
 #else
 		return -EOPNOTSUPP;
@@ -750,6 +924,8 @@ void pci_msix_shutdown(struct pci_dev *d
 void pci_disable_msix(struct pci_dev *dev)
 {
 	pci_msix_shutdown(dev);
+	kset_unregister(dev->msi_kset);
+	dev->msi_kset = NULL;
 }
 EXPORT_SYMBOL(pci_disable_msix);
 
@@ -775,14 +951,14 @@ void msi_remove_pci_irq_vectors(struct p
 
 	spin_lock_irqsave(&msi_dev_entry->pirq_list_lock, flags);
 	list_for_each_entry_safe(pirq_entry, tmp, &dev->msi_list, list) {
-		if (is_initial_xendomain())
-			msi_unmap_pirq(dev, pirq_entry->pirq);
-		else
-			evtchn_map_pirq(pirq_entry->pirq, 0);
+		msi_unmap_pirq(dev, pirq_entry->pirq,
+			       msi_dev_entry->owner,
+			       &pirq_entry->kobj);
 		list_del(&pirq_entry->list);
 		kfree(pirq_entry);
 	}
 	spin_unlock_irqrestore(&msi_dev_entry->pirq_list_lock, flags);
+	msi_dev_entry->owner = DOMID_IO;
 	dev->irq = msi_dev_entry->default_irq;
 }
 
