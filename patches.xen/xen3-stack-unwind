Subject: xen: DWARF2 EH-frame based stack unwinding
From: jbeulich@suse.com
Patch-mainline: Never, SUSE-Xen specific

This includes reverting f1883f86dea84fe47a71a39fc1afccc005915ed8.

Update Sep 18 2008 andi:
- suppress FRAME_POINTER select
Update Jan 17 2009 jeffm:
- Something in 2.6.29-rc1 tweaked the frame pointer code somehow, so I fixed
  that up.
Update Jul 02 2010 jbeulich:
- fix after upstream commit 9e565292270a2d55524be38835104c564ac8f795
Update Sep 15 2011 jbeulich:
- add support for DW_CFA_def_cfa_expression (needed by x86-64)
Update Nov 24 2011 jeffm:
- cfi_ignore takes more arguments
Update Aug 01 2012 jbeulich:
- mark unwind section start/end symbols as always relative
Update Apr 28 2014 jeffm:
- remove ix86 check for vdso32 compat range
Update Jun 24 2014 jeffm:
- VSYSCALL_START / END replaced upstream with
  VSYSCALL_ADDR / VSYSCALL_ADDR + PAGE_SIZE
Update Sep 22 2015 jslaby:
- Enablement after manual dwarf annotations are gone from upstream

TODO:
* annotate arch_unwind_init_running by FRAME_BEGIN/END in both entry_32/64.S.
  (Only after stacktool is merged.)
* assembler not unwound properly, as annotations are gone -- frame ptr is used
  for the rest of the stack instead (as always).

Automatically created from "patches.suse/stack-unwind" by xen-port-patches.py

--- a/arch/x86/entry/entry_32-xen.S
+++ b/arch/x86/entry/entry_32-xen.S
@@ -896,6 +896,39 @@ ENTRY(fixup_4gb_segment)
 	jmp error_code
 END(fixup_4gb_segment)
 
+#ifdef CONFIG_STACK_UNWIND
+ENTRY(arch_unwind_init_running)
+	movl	4(%esp), %edx
+	movl	(%esp), %ecx
+	leal	4(%esp), %eax
+	movl	%ebx, PT_EBX(%edx)
+	xorl	%ebx, %ebx
+	movl	%ebx, PT_ECX(%edx)
+	movl	%ebx, PT_EDX(%edx)
+	movl	%esi, PT_ESI(%edx)
+	movl	%edi, PT_EDI(%edx)
+	movl	%ebp, PT_EBP(%edx)
+	movl	%ebx, PT_EAX(%edx)
+	movl	$__USER_DS, PT_DS(%edx)
+	movl	$__USER_DS, PT_ES(%edx)
+	movl	$__KERNEL_PERCPU, PT_FS(%edx)
+	movl	$__KERNEL_STACK_CANARY, PT_GS(%edx)
+	movl	%eax, PT_OLDESP(%edx)
+	movl	16(%esp), %eax
+	movl	%ebx, PT_ORIG_EAX(%edx)
+	movl	%ecx, PT_EIP(%edx)
+	movl	12(%esp), %ecx
+	movl	$__KERNEL_CS, PT_CS(%edx)
+	movl	%eax, 12(%esp)
+	movl	8(%esp), %eax
+	movl	%ecx, 8(%esp)
+	movl	%ebx, PT_EFLAGS(%edx)
+	movl	PT_EBX(%edx), %ebx
+	movl	$__KERNEL_DS, PT_OLDSS(%edx)
+	jmpl	*%eax
+ENDPROC(arch_unwind_init_running)
+#endif
+
 #ifdef CONFIG_FUNCTION_TRACER
 #ifdef CONFIG_DYNAMIC_FTRACE
 
--- a/arch/x86/entry/entry_64-xen.S
+++ b/arch/x86/entry/entry_64-xen.S
@@ -666,6 +666,38 @@ ENTRY(do_softirq_own_stack)
 	ret
 END(do_softirq_own_stack)
 
+#ifdef CONFIG_STACK_UNWIND
+ENTRY(arch_unwind_init_running)
+	movq	%r15, R15(%rdi)
+	movq	%r14, R14(%rdi)
+	xchgq	%rsi, %rdx
+	movq	%r13, R13(%rdi)
+	movq	%r12, R12(%rdi)
+	xorl	%eax, %eax
+	movq	%rbp, RBP(%rdi)
+	movq	%rbx, RBX(%rdi)
+	movq	(%rsp), %r9
+	xchgq	%rdx, %rcx
+	movq	%rax, R11(%rdi)
+	movq	%rax, R10(%rdi)
+	movq	%rax, R9(%rdi)
+	movq	%rax, R8(%rdi)
+	movq	%rax, RAX(%rdi)
+	movq	%rax, RCX(%rdi)
+	movq	%rax, RDX(%rdi)
+	movq	%rax, RSI(%rdi)
+	movq	%rax, RDI(%rdi)
+	movq	%rax, ORIG_RAX(%rdi)
+	movq	%r9, RIP(%rdi)
+	leaq	8(%rsp), %r9
+	movq	$__KERNEL_CS, CS(%rdi)
+	movq	%rax, EFLAGS(%rdi)
+	movq	%r9, RSP(%rdi)
+	movq	$__KERNEL_DS, SS(%rdi)
+	jmpq	*%rcx
+END(arch_unwind_init_running)
+#endif
+
 idtentry debug			do_debug		has_error_code=0
 idtentry nmi			do_nmi_callback		has_error_code=0
 idtentry int3			do_int3			has_error_code=0
