From: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
Date: Mon, 18 Apr 2016 14:34:05 +0300
Subject: net/mlx4_en: do batched put_page using atomic_sub
Patch-mainline: v4.6-rc5
Git-commit: 851b10d60879539bec8acecb35ed361393399282
References: bsc#966191 FATE#320230 bsc#966186 FATE#320228

This patch fixes couple error paths after allocation failures.
Atomic set of page reference counter is safe only if it is zero,
otherwise set can race with any speculative get_page_unless_zero.

Signed-off-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
Signed-off-by: David S. Miller <davem@davemloft.net>
[ bpoirier: replaced page_ref_sub by atomic_sub, see fe896d1 ]
Signed-off-by: Benjamin Poirier <bpoirier@suse.com>
---
 drivers/net/ethernet/mellanox/mlx4/en_rx.c |    9 +++++++--
 1 file changed, 7 insertions(+), 2 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx4/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_rx.c
@@ -127,7 +127,10 @@ out:
 			dma_unmap_page(priv->ddev, page_alloc[i].dma,
 				page_alloc[i].page_size, PCI_DMA_FROMDEVICE);
 			page = page_alloc[i].page;
-			atomic_set(&page->_count, 1);
+			/* Revert changes done by mlx4_alloc_pages */
+			atomic_sub(page_alloc[i].page_size /
+				   priv->frag_info[i].frag_stride - 1,
+				   &page->_count);
 			put_page(page);
 		}
 	}
@@ -177,7 +180,9 @@ out:
 		dma_unmap_page(priv->ddev, page_alloc->dma,
 			       page_alloc->page_size, PCI_DMA_FROMDEVICE);
 		page = page_alloc->page;
-		atomic_set(&page->_count, 1);
+		/* Revert changes done by mlx4_alloc_pages */
+		atomic_sub(page_alloc->page_size /
+			   priv->frag_info[i].frag_stride - 1, &page->_count);
 		put_page(page);
 		page_alloc->page = NULL;
 	}
