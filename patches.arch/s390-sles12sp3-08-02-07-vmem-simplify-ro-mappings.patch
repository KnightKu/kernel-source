From: Martin Schwidefsky <schwidefsky@de.ibm.com>
Subject: s390/vmem: simplify vmem code for read-only mappings
Patch-mainline: v4.8-rc1
Git-commit: bab247ff5f669216e3ed2f9a4034c540187e874c
References: FATE#324087, LTC#158827

Summary:     kernel: instruction execution protection
Description: Instruction execution protection is designed to enhance
             reliability and security. It prevents the execution of
             instructions in virtual memory locations that are not
             intended to contain instructions. 

Upstream-Description:

             s390/vmem: simplify vmem code for read-only mappings

             For the kernel identity mapping map everything read-writeable and
             subsequently call set_memory_ro() to make the ro section read-only.
             This simplifies the code a lot.

             Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
             Acked-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
             Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>


Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
Acked-by: Johannes Thumshirn <jthumshirn@suse.de>
---
 arch/s390/mm/vmem.c |   36 ++++++++----------------------------
 1 file changed, 8 insertions(+), 28 deletions(-)

--- a/arch/s390/mm/vmem.c
+++ b/arch/s390/mm/vmem.c
@@ -77,7 +77,7 @@ pte_t __ref *vmem_pte_alloc(unsigned lon
 /*
  * Add a physical memory range to the 1:1 mapping.
  */
-static int vmem_add_mem(unsigned long start, unsigned long size, int ro)
+static int vmem_add_mem(unsigned long start, unsigned long size)
 {
 	unsigned long end = start + size;
 	unsigned long address = start;
@@ -99,8 +99,7 @@ static int vmem_add_mem(unsigned long st
 #ifndef CONFIG_DEBUG_PAGEALLOC
 		if (MACHINE_HAS_EDAT2 && pud_none(*pu_dir) && address &&
 		    !(address & ~PUD_MASK) && (address + PUD_SIZE <= end)) {
-			pud_val(*pu_dir) = address |
-				pgprot_val(ro ? REGION3_KERNEL_RO : REGION3_KERNEL);
+			pud_val(*pu_dir) = address | pgprot_val(REGION3_KERNEL);
 			address += PUD_SIZE;
 			continue;
 		}
@@ -115,8 +114,7 @@ static int vmem_add_mem(unsigned long st
 #ifndef CONFIG_DEBUG_PAGEALLOC
 		if (MACHINE_HAS_EDAT1 && pmd_none(*pm_dir) && address &&
 		    !(address & ~PMD_MASK) && (address + PMD_SIZE <= end)) {
-			pmd_val(*pm_dir) = address |
-				pgprot_val(ro ? SEGMENT_KERNEL_RO : SEGMENT_KERNEL);
+			pmd_val(*pm_dir) = address | pgprot_val(SEGMENT_KERNEL);
 			address += PMD_SIZE;
 			continue;
 		}
@@ -129,8 +127,7 @@ static int vmem_add_mem(unsigned long st
 		}
 
 		pt_dir = pte_offset_kernel(pm_dir, address);
-		pte_val(*pt_dir) = address |
-			pgprot_val(ro ? PAGE_KERNEL_RO : PAGE_KERNEL);
+		pte_val(*pt_dir) = address |  pgprot_val(PAGE_KERNEL);
 		address += PAGE_SIZE;
 	}
 	ret = 0;
@@ -342,7 +339,7 @@ int vmem_add_mapping(unsigned long start
 	if (ret)
 		goto out_free;
 
-	ret = vmem_add_mem(start, size, 0);
+	ret = vmem_add_mem(start, size);
 	if (ret)
 		goto out_remove;
 	goto out;
@@ -365,29 +362,12 @@ void __init vmem_map_init(void)
 {
 	unsigned long ro_start, ro_end;
 	struct memblock_region *reg;
-	phys_addr_t start, end;
 
+	for_each_memblock(memory, reg)
+		vmem_add_mem(reg->base, reg->size);
 	ro_start = PFN_ALIGN((unsigned long)&_stext);
 	ro_end = (unsigned long)&_eshared & PAGE_MASK;
-	for_each_memblock(memory, reg) {
-		start = reg->base;
-		end = reg->base + reg->size;
-		if (start >= ro_end || end <= ro_start)
-			vmem_add_mem(start, end - start, 0);
-		else if (start >= ro_start && end <= ro_end)
-			vmem_add_mem(start, end - start, 1);
-		else if (start >= ro_start) {
-			vmem_add_mem(start, ro_end - start, 1);
-			vmem_add_mem(ro_end, end - ro_end, 0);
-		} else if (end < ro_end) {
-			vmem_add_mem(start, ro_start - start, 0);
-			vmem_add_mem(ro_start, end - ro_start, 1);
-		} else {
-			vmem_add_mem(start, ro_start - start, 0);
-			vmem_add_mem(ro_start, ro_end - ro_start, 1);
-			vmem_add_mem(ro_end, end - ro_end, 0);
-		}
-	}
+	set_memory_ro(ro_start, (ro_end - ro_start) >> PAGE_SHIFT);
 }
 
 /*
