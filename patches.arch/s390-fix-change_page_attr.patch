From: martin.schwidefsky@de.ibm.com
Subject: s390/pageattr: Do a single TLB flush for change_page_attr
References: bsc#940413
Patch-mainline: v4.6
Git-commit: 007ccec53da35528bd06fa0063da55b1311054c1

The change of the access rights for an address range in the kernel
address space is currently done with a loop of IPTE + a store of the
modified PTE. Between the IPTE and the store the PTE will be invalid,
this intermediate state can cause problems with concurrent accesses.

Consider a change of a kernel area from read-write to read-only, a
concurrent reader of that area should be fine but with the invalid
PTE it might get an unexpected exception.

Remove the IPTEs for each PTE and do a global flush after all PTEs
have been modified.

Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
Acked-by: Jean Delvare <jdelvare@suse.de>
---
 arch/s390/mm/pageattr.c |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

--- a/arch/s390/mm/pageattr.c
+++ b/arch/s390/mm/pageattr.c
@@ -57,10 +57,10 @@ static void change_page_attr(unsigned lo
 
 		pte = *ptep;
 		pte = set(pte);
-		__ptep_ipte(addr, ptep);
 		*ptep = pte;
 		addr += PAGE_SIZE;
 	}
+	__tlb_flush_global();
 }
 
 int set_memory_ro(unsigned long addr, int numpages)
