From: Jiri Slaby <jslaby@suse.cz>
Date: Mon, 6 Jan 2014 09:35:56 +0100
Subject: kgr: kthreads support
Patch-mainline: not yet, kgraft
References: fate#313296

Wake up kthreads so that they cycle through klp_kgraft_mark_task_safe
either by an explicit call to it or implicitly via try_to_freeze. This
ensures nobody should use the old version of the code and kgraft core
can push everybody to use the new version by switching to the fast
path.

jk: proper test for a process being a kthread
mb: fix migration of kthreads to the new universe

Signed-off-by: Jiri Kosina <jkosina@suse.cz> [fixes]
Signed-off-by: Miroslav Benes <mbenes@suse.cz> [fixes]
Signed-off-by: Jiri Slaby <jslaby@suse.cz>
Cc: Tejun Heo <tj@kernel.org>
Cc: Steven Rostedt <rostedt@goodmis.org>
Cc: Frederic Weisbecker <fweisbec@gmail.com>
Cc: Ingo Molnar <mingo@redhat.com>
---
 kernel/kgraft.c |   46 +++++++++++++++++++++++++++++++++++-----------
 1 file changed, 35 insertions(+), 11 deletions(-)

--- a/kernel/kgraft.c
+++ b/kernel/kgraft.c
@@ -70,9 +70,7 @@ static notrace void kgr_stub_slow(unsign
 	struct kgr_patch_fun *p = ops->private;
 	bool go_new;
 
-	if (current->flags & PF_KTHREAD) {
-		go_new = true;
-	} else if (test_bit(0, kgr_immutable)) {
+	if (test_bit(0, kgr_immutable)) {
 		klp_kgraft_mark_task_in_progress(current);
 		go_new = false;
 	} else {
@@ -125,12 +123,7 @@ static bool kgr_still_patching(void)
 
 	read_lock(&tasklist_lock);
 	for_each_process_thread(p, t) {
-		/*
-		 * TODO
-		 *   kernel thread codepaths not supported and silently ignored
-		 */
-		if (klp_kgraft_task_in_progress(t) &&
-				!(t->flags & PF_KTHREAD)) {
+		if (klp_kgraft_task_in_progress(t)) {
 			failed = true;
 			goto unlock;
 		}
@@ -203,6 +196,32 @@ static void kgr_handle_processes(void)
 	read_unlock(&tasklist_lock);
 }
 
+static void kgr_wakeup_kthreads(void)
+{
+	struct task_struct *p, *t;
+
+	read_lock(&tasklist_lock);
+	for_each_process_thread(p, t) {
+		/*
+		 * Wake up kthreads, they will clean the progress flag.
+		 *
+		 * There is a small race here. We could see TIF_KGR_IN_PROGRESS
+		 * set and decide to wake up a kthread. Meanwhile the kthread
+		 * could migrate itself and the waking up would be meaningless.
+		 * It is not serious though.
+		 */
+		if ((t->flags & PF_KTHREAD) &&
+				klp_kgraft_task_in_progress(t)) {
+			/*
+			 * this is incorrect for kthreads waiting still for
+			 * their first wake_up.
+			 */
+			wake_up_process(t);
+		}
+	}
+	read_unlock(&tasklist_lock);
+}
+
 static unsigned long kgr_get_function_address(const struct kgr_patch_fun *pf)
 {
 	unsigned long orig_addr;
@@ -404,6 +423,12 @@ int kgr_modify_kernel(struct kgr_patch *
 	clear_bit(0, kgr_immutable);
 
 	/*
+	 * There is no need to have an explicit barrier here. wake_up_process()
+	 * implies a write barrier. That is every woken up task sees
+	 * kgr_immutable cleared.
+	 */
+	kgr_wakeup_kthreads();
+	/*
 	 * give everyone time to exit kernel, and check after a while
 	 */
 	queue_delayed_work(kgr_wq, &kgr_work, KGR_TIMEOUT * HZ);
@@ -419,8 +444,7 @@ err_unlock:
  * kgr_patch_kernel -- the entry for a kgraft patch
  * @patch: patch to be applied
  *
- * Start patching of code that is neither running in IRQ context nor
- * kernel thread.
+ * Start patching of code that is not running in IRQ context.
  */
 int kgr_patch_kernel(struct kgr_patch *patch)
 {
