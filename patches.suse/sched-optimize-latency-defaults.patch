Subject: sched: optimize latency defaults
From: Mike Galbraith <mgalbraith@suse.de>
Date: Tue Jun 12 07:23:26 CEST 2012
Patch-mainline: never, SUSE specific
References: Scheduler enhancements for I7 (bnc#754690)

Adjust latency defaults to match SLE11-SP3:

1. sched_latency = 6ms, ie 3.0 stock
2. min_granularity = 2ms
   This setting sets nr_ latency to 3, switching the scheduler to cache
   preservation strategy sooner.  LAST_BUDDY uses this to try to give
   the CPU back to a wakeup preempted task, preserving it's footprint
   should a fast mover (ala kthread) briefly preempt, thus preventing
   selection of another task on every preempt, and trashing cache.
3. wakeup_granularity = 2.5ms.
   Reduces wakeup preemption to minimum, thus reducing overscheduling.

Fundamental problem with SP1 wide latency target: our preemption model
is sleep based, which is based upon our latency target.  While sleep
is a very natural preemption metric, there is a fundamental problem
with it: as resource contention increases, so does total sleep time,
rendering it less and less effective as a differentiator as load climbs.
Ergo, when tuning for loaded box performance, it has to be set to the
minimum that still allows preemption to occurr, to minimize thrash.

To date, noone has presented a model that is as cheap as and works
better than Linus' sleep time model despite it's limitations, so here
we sit with a good but not "perfect is the enemy of good" preempt
model in a scheduler.. that tries to be.. perfectly.. fair with all
that implies.

Signed-off-by: Mike Galbraith <mgalbraith@suse.de>
---
 kernel/sched/fair.c |   14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -63,15 +63,15 @@ enum sched_tunable_scaling sysctl_sched_
 
 /*
  * Minimal preemption granularity for CPU-bound tasks:
- * (default: 0.75 msec * (1 + ilog(ncpus)), units: nanoseconds)
+ * (default: 2 msec * (1 + ilog(ncpus)), units: nanoseconds)
  */
-unsigned int sysctl_sched_min_granularity = 750000ULL;
-unsigned int normalized_sysctl_sched_min_granularity = 750000ULL;
+unsigned int sysctl_sched_min_granularity = 2000000ULL;
+unsigned int normalized_sysctl_sched_min_granularity = 2000000ULL;
 
 /*
  * is kept at sysctl_sched_latency / sysctl_sched_min_granularity
  */
-static unsigned int sched_nr_latency = 8;
+static unsigned int sched_nr_latency = 3;
 
 /*
  * After fork, child runs first. If set to 0 (default) then
@@ -81,14 +81,14 @@ unsigned int sysctl_sched_child_runs_fir
 
 /*
  * SCHED_OTHER wake-up granularity.
- * (default: 1 msec * (1 + ilog(ncpus)), units: nanoseconds)
+ * (default: 2.5 msec * (1 + ilog(ncpus)), units: nanoseconds)
  *
  * This option delays the preemption effects of decoupled workloads
  * and reduces their over-scheduling. Synchronous workloads will still
  * have immediate wakeup/sleep latencies.
  */
-unsigned int sysctl_sched_wakeup_granularity = 1000000UL;
-unsigned int normalized_sysctl_sched_wakeup_granularity = 1000000UL;
+unsigned int sysctl_sched_wakeup_granularity = 2500000UL;
+unsigned int normalized_sysctl_sched_wakeup_granularity = 2500000UL;
 
 const_debug unsigned int sysctl_sched_migration_cost = 500000UL;
 
