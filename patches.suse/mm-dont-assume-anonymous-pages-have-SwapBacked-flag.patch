From: Shaohua Li <shli@fb.com>
Subject: mm: don't assume anonymous pages have SwapBacked flag
Patch-mainline: not yet, in mmotm tree, should be in 4.12
References: bnc#1027383

There are a few places the code assumes anonymous pages should have
SwapBacked flag set. MADV_FREE pages are anonymous pages but we are
going to add them to LRU_INACTIVE_FILE list and clear SwapBacked flag
for them. The assumption doesn't hold any more, so fix them.

Cc: Minchan Kim <minchan@kernel.org>
Cc: Hugh Dickins <hughd@google.com>
Cc: Rik van Riel <riel@redhat.com>
Cc: Mel Gorman <mgorman@techsingularity.net>
Cc: Andrew Morton <akpm@linux-foundation.org>
Acked-by: Johannes Weiner <hannes@cmpxchg.org>
Signed-off-by: Shaohua Li <shli@fb.com>
Signed-off-by: Michal Hocko <mhocko@suse.cz>

---
 mm/huge_memory.c |    9 +++------
 mm/migrate.c     |    3 ++-
 mm/rmap.c        |    2 +-
 3 files changed, 6 insertions(+), 8 deletions(-)

--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -1992,6 +1992,7 @@ int split_huge_page_to_list(struct page
 
 	BUG_ON(is_huge_zero_page(page));
 	BUG_ON(!PageAnon(page));
+	BUG_ON(!PageSwapBacked(page));
 
 	/*
 	 * The caller does not necessarily hold an mmap_sem that would prevent
@@ -2009,7 +2010,6 @@ int split_huge_page_to_list(struct page
 	if (!PageCompound(page))
 		goto out_unlock;
 
-	BUG_ON(!PageSwapBacked(page));
 	__split_huge_page(page, anon_vma, list);
 	count_vm_event(THP_SPLIT);
 
@@ -2209,8 +2209,7 @@ void __khugepaged_exit(struct mm_struct
 
 static void release_pte_page(struct page *page)
 {
-	/* 0 stands for page_is_file_cache(page) == false */
-	dec_zone_page_state(page, NR_ISOLATED_ANON + 0);
+	dec_zone_page_state(page, NR_ISOLATED_ANON + page_is_file_cache(page));
 	unlock_page(page);
 	putback_lru_page(page);
 }
@@ -2251,7 +2250,6 @@ static int __collapse_huge_page_isolate(
 
 		VM_BUG_ON_PAGE(PageCompound(page), page);
 		VM_BUG_ON_PAGE(!PageAnon(page), page);
-		VM_BUG_ON_PAGE(!PageSwapBacked(page), page);
 
 		/*
 		 * We can do it before isolate_lru_page because the
@@ -2292,8 +2290,7 @@ static int __collapse_huge_page_isolate(
 			unlock_page(page);
 			goto out;
 		}
-		/* 0 stands for page_is_file_cache(page) == false */
-		inc_zone_page_state(page, NR_ISOLATED_ANON + 0);
+		inc_zone_page_state(page, NR_ISOLATED_ANON + page_is_file_cache(page));
 		VM_BUG_ON_PAGE(!PageLocked(page), page);
 		VM_BUG_ON_PAGE(PageLRU(page), page);
 
--- a/mm/migrate.c
+++ b/mm/migrate.c
@@ -1782,7 +1782,8 @@ int migrate_misplaced_transhuge_page(str
 
 	/* Prepare a page as a migration target */
 	__set_page_locked(new_page);
-	SetPageSwapBacked(new_page);
+	if (PageSwapBacked(page))
+		__SetPageSwapBacked(new_page);
 
 	/* anon mapping, we can simply copy page->mapping to the new page: */
 	new_page->mapping = page->mapping;
--- a/mm/rmap.c
+++ b/mm/rmap.c
@@ -1385,7 +1385,7 @@ static int try_to_unmap_one(struct page
 		 * Store the swap location in the pte.
 		 * See handle_pte_fault() ...
 		 */
-		VM_BUG_ON_PAGE(!PageSwapCache(page), page);
+		VM_BUG_ON_PAGE(!PageSwapCache(page) && PageSwapBacked(page), page);
 
 		if (!PageDirty(page)) {
 			/* It's a freeable page by MADV_FREE */
