From: Tim Chen <tim.c.chen@linux.intel.com>
Date: Sat, 16 Dec 2017 19:01:26 +0100
Subject: x86/entry: Stuff RSB for entry to kernel for non-SMEP platform
Patch-mainline: submitted on 2018/1/9
References: bsc#1068032

Stuff RSB to prevent RSB underflow on non-SMEP platforms.

Signed-off-by: Tim Chen <tim.c.chen@linux.intel.com>
Signed-off-by: Borislav Petkov <bp@suse.de>
---
 arch/x86/ia32/ia32entry.S  |    3 +++
 arch/x86/kernel/entry_64.S |   10 ++++++++++
 2 files changed, 13 insertions(+)

--- a/arch/x86/ia32/ia32entry.S
+++ b/arch/x86/ia32/ia32entry.S
@@ -150,6 +150,7 @@ ENTRY(ia32_sysenter_target)
 	cld
 
 	ENABLE_IBRS
+	STUFF_RSB
 
 	SAVE_ARGS 0,0,1
  	/* no need to do an access_ok check here because rbp has been
@@ -317,6 +318,7 @@ ENTRY(ia32_cstar_target)
 	CFI_REL_OFFSET rsp,RSP-ARGOFFSET
 
 	ENABLE_IBRS
+	STUFF_RSB
 
 	/* no need to do an access_ok check here because r8 has been
 	   32bit zero extended */ 
@@ -446,6 +448,7 @@ ENTRY(ia32_syscall)
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%r10)
 
 	ENABLE_IBRS
+	STUFF_RSB
 
 	jnz ia32_tracesys
 	cmpq $(IA32_NR_syscalls-1),%rax
--- a/arch/x86/kernel/entry_64.S
+++ b/arch/x86/kernel/entry_64.S
@@ -333,6 +333,7 @@ ENTRY(save_args)
 	SWAPGS
 	SWITCH_KERNEL_CR3
 	ENABLE_IBRS
+	STUFF_RSB
 	/*
 	 * irq_count is used to check if a CPU is already on an interrupt stack
 	 * or not. While this is essentially redundant with preempt_count it is
@@ -395,6 +396,10 @@ ENTRY(save_paranoid)
 	movq %r13, R13+8(%rsp)
 	movq %r14, R14+8(%rsp)
 	movq %r15, R15+8(%rsp)
+
+	/* Do the stuffing unconditionally from user/kernel to be safe */
+	STUFF_RSB
+
 	movl $1,%ebx
 	movl $MSR_GS_BASE,%ecx
 	rdmsr
@@ -523,6 +528,7 @@ ENTRY(system_call_after_swapgs)
 	GET_THREAD_INFO(%rcx)
 
 	ENABLE_IBRS
+	STUFF_RSB
 
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%rcx)
 	jnz tracesys
@@ -959,6 +965,7 @@ native_irq_return_ldt:
 	SWITCH_KERNEL_CR3
 
 	ENABLE_IBRS
+	STUFF_RSB
 
 	movq PER_CPU_VAR(espfix_waddr),%rdi
 	movq %rax,(0*8)(%rdi)	/* RAX */
@@ -1598,6 +1605,9 @@ ENTRY(error_entry)
 	movq %r13, R13+8(%rsp)
 	movq %r14, R14+8(%rsp)
 	movq %r15, R15+8(%rsp)
+
+	STUFF_RSB
+
 	/*
 	 * error_entry() always returns with a kernel gsbase and
 	 * CR3.  We must also have a kernel CR3/gsbase before
