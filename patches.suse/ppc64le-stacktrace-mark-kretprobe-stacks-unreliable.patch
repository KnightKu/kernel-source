From: Nicolai Stange <nstange@suse.de>
Subject: ppc64le: reliable stacktrace: mark stacktraces with kretprobe_trampoline as unreliable
Patch-mainline: Never, temporary fix to get things going here
References: bsc#1090522

kretprobes are implemented by temporarily redirecting a function's return
address to the kretprobe_trampoline stub. This causes the reliable
stacktrace implementation to miss callers of kretprobed functions.

Do what x86_64 (ORC unwinder) does and mark stacktraces with
kretprobe_trampoline on them as unreliable.

Note that this is a temporary fix for
suse-commit a4da14cfd7a8 ("On ppc64le we HAVE_RELIABLE_STACKTRACE")
which is likely to get reworked anyway.

Signed-off-by: Nicolai Stange <nstange@suse.de>
---
 arch/powerpc/kernel/stacktrace.c |    8 ++++++++
 1 file changed, 8 insertions(+)

--- a/arch/powerpc/kernel/stacktrace.c
+++ b/arch/powerpc/kernel/stacktrace.c
@@ -21,6 +21,7 @@
 #include <asm/processor.h>
 #ifndef __GENKSYMS__
 #include <linux/ftrace.h>
+#include <asm/kprobes.h>
 #endif
 
 /*
@@ -165,6 +166,13 @@ save_stack_trace_tsk_reliable(struct tas
 
 		ip = ftrace_graph_ret_addr(tsk, &graph_idx, ip, NULL);
 
+		/*
+		 * Mark stacktraces with kretprobed functions on them
+		 * as unreliable.
+		 */
+		if (ip == (unsigned long)kretprobe_trampoline)
+			return 1;
+
 		if (!trace->skip)
 			trace->entries[trace->nr_entries++] = ip;
 		else
