From: Jiri Slaby <jslaby@suse.cz>
Date: Thu, 30 Jan 2014 17:21:49 +0100
Subject: kgr: handle irqs
Patch-mainline: submitted for review
References: fate#313296

Introduce a per-cpu flag to check whether we should use the old or new
function in the slow stub. The new function starts being used on a
processor only after a scheduled function sets the flag via
schedule_on_each_cpu. Presumably this happens in the process context,
no irq is running. And protect the flag setting by disabling
interrupts so that we 1) have a barrier and 2) no interrupt triggers
while setting the flag (but the set should be atomic anyway as it is
bool).

js: fix fail paths
js: make the logic more readable
js: fix allocation order

Signed-off-by: Jiri Slaby <jslaby@suse.cz>
Cc: Steven Rostedt <rostedt@goodmis.org>
Cc: Frederic Weisbecker <fweisbec@gmail.com>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
---
 include/linux/kgraft.h |  9 +++++++++
 kernel/kgraft.c        | 41 ++++++++++++++++++++++++++++++++++++++---
 2 files changed, 47 insertions(+), 3 deletions(-)

diff --git a/include/linux/kgraft.h b/include/linux/kgraft.h
index 04901c27f561..367feb42dfc4 100644
--- a/include/linux/kgraft.h
+++ b/include/linux/kgraft.h
@@ -18,6 +18,7 @@
 #define LINUX_KGR_H
 
 #include <linux/bitops.h>
+#include <linux/compiler.h>
 #include <linux/ftrace.h>
 #include <linux/sched.h>
 
@@ -27,6 +28,8 @@
 
 #define KGR_TIMEOUT 30
 
+struct kgr_patch;
+
 /**
  * struct kgr_patch_fun -- state of a single function in a kGraft patch
  *
@@ -38,6 +41,8 @@
  * @ftrace_ops_fast: ftrace ops for fast () stub
  */
 struct kgr_patch_fun {
+	struct kgr_patch *patch;
+
 	const char *name;
 	void *new_fun;
 
@@ -51,10 +56,14 @@ struct kgr_patch_fun {
 /**
  * struct kgr_patch -- a kGraft patch
  *
+ * @irq_use_new: per-cpu array to remember kGraft state for interrupts
  * @owner: module to refcount on patching
  * @patches: array of @kgr_patch_fun structures
  */
 struct kgr_patch {
+	/* internal state information */
+	bool __percpu *irq_use_new;
+
 	/* a patch shall set these */
 	struct module *owner;
 	struct kgr_patch_fun patches[];
diff --git a/kernel/kgraft.c b/kernel/kgraft.c
index 6a42f77f3be5..c7d4680b0591 100644
--- a/kernel/kgraft.c
+++ b/kernel/kgraft.c
@@ -15,9 +15,11 @@
  */
 
 #include <linux/ftrace.h>
+#include <linux/hardirq.h> /* for in_interrupt() */
 #include <linux/kallsyms.h>
 #include <linux/kgraft.h>
 #include <linux/module.h>
+#include <linux/percpu.h>
 #include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/sort.h>
@@ -52,7 +54,12 @@ static void kgr_stub_slow(unsigned long ip, unsigned long parent_ip,
 		struct ftrace_ops *ops, struct pt_regs *regs)
 {
 	struct kgr_patch_fun *p = ops->private;
-	bool go_old = kgr_task_in_progress(current);
+	bool go_old;
+
+	if (in_interrupt())
+		go_old = !*this_cpu_ptr(p->patch->irq_use_new);
+	else
+		go_old = kgr_task_in_progress(current);
 
 	if (go_old) {
 		pr_debug("kgr: slow stub: calling old code at %lx\n",
@@ -124,6 +131,8 @@ static void kgr_finalize(void)
 					patch_fun->name);
 	}
 
+	free_percpu(kgr_patch->irq_use_new);
+
 	mutex_lock(&kgr_in_progress_lock);
 	kgr_in_progress = false;
 	mutex_unlock(&kgr_in_progress_lock);
@@ -195,6 +204,20 @@ static unsigned long kgr_get_fentry_loc(const char *f_name)
 	return fentry_loc;
 }
 
+static void kgr_handle_irq_cpu(struct work_struct *work)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	*this_cpu_ptr(kgr_patch->irq_use_new) = true;
+	local_irq_restore(flags);
+}
+
+static void kgr_handle_irqs(void)
+{
+	schedule_on_each_cpu(kgr_handle_irq_cpu);
+}
+
 static int kgr_init_ftrace_ops(struct kgr_patch_fun *patch_fun)
 {
 	struct ftrace_ops *fops;
@@ -286,7 +309,7 @@ static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final)
  * kgr_patch_kernel -- the entry for a kgraft patch
  * @patch: patch to be applied
  *
- * Start patching of code that is not running in IRQ context.
+ * Start patching of code.
  */
 int kgr_patch_kernel(struct kgr_patch *patch)
 {
@@ -310,7 +333,16 @@ int kgr_patch_kernel(struct kgr_patch *patch)
 		goto err_unlock;
 	}
 
+	patch->irq_use_new = alloc_percpu(bool);
+	if (!patch->irq_use_new) {
+		pr_err("kgr: can't patch, cannot allocate percpu data\n");
+		ret = -ENOMEM;
+		goto err_unlock;
+	}
+
 	kgr_for_each_patch_fun(patch, patch_fun) {
+		patch_fun->patch = patch;
+
 		ret = kgr_patch_code(patch_fun, false);
 		/*
 		 * In case any of the symbol resolutions in the set
@@ -322,13 +354,14 @@ int kgr_patch_kernel(struct kgr_patch *patch)
 					patch_fun--)
 				kgr_ftrace_disable(patch_fun,
 						&patch_fun->ftrace_ops_slow);
-			goto err_unlock;
+			goto err_free;
 		}
 	}
 	kgr_in_progress = true;
 	kgr_patch = patch;
 	mutex_unlock(&kgr_in_progress_lock);
 
+	kgr_handle_irqs();
 	kgr_handle_processes();
 
 	/*
@@ -337,6 +370,8 @@ int kgr_patch_kernel(struct kgr_patch *patch)
 	queue_delayed_work(kgr_wq, &kgr_work, 10 * HZ);
 
 	return 0;
+err_free:
+	free_percpu(patch->irq_use_new);
 err_unlock:
 	mutex_unlock(&kgr_in_progress_lock);
 	module_put(patch->owner);
-- 
2.0.4

