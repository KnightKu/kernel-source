From 21dc56bf19d78eb68a8c07a7aacdc97e57572b7b Mon Sep 17 00:00:00 2001
From: Mel Gorman <mgorman@suse.de>
Date: Wed, 9 Apr 2014 14:25:25 +0100
Subject: [PATCH] paravirt: Split paravirt MMU ops

References: bnc#556135, bnc#754690, FATE#306453
Patch-mainline: Never, should have been replaced upstream already

Currently using paravirt ops is mostly an all-or-nothing approach and
tends towards the "all" end of the scale.

There are use cases which do not need the full feature set and the MMU
operations in particular are not needed in many cases but is impossible
to cherry pick on its own.

This patch creates a KVM_MMU and PARAVIRT_MMU option that allows
paravirtualisation support to be configured out if necessary.

All credit goes to Alaxander Graf whose work this patch is completely
based on.

Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 arch/x86/Kconfig                            |    9 +++++++++
 arch/x86/include/asm/fixmap.h               |    2 +-
 arch/x86/include/asm/mmu_context.h          |    4 ++--
 arch/x86/include/asm/paravirt.h             |    8 ++++++++
 arch/x86/include/asm/paravirt_types.h       |    2 ++
 arch/x86/include/asm/pgalloc.h              |    2 +-
 arch/x86/include/asm/pgtable-3level_types.h |    2 +-
 arch/x86/include/asm/pgtable.h              |    2 +-
 arch/x86/include/asm/special_insns.h        |    7 ++++++-
 arch/x86/include/asm/tlbflush.h             |    4 ++--
 arch/x86/kernel/head_64.S                   |    2 +-
 arch/x86/kernel/paravirt.c                  |    8 +++++++-
 arch/x86/kernel/paravirt_patch_32.c         |    4 ++++
 arch/x86/kernel/paravirt_patch_64.c         |    6 +++++-
 arch/x86/xen/Kconfig                        |    1 +
 15 files changed, 51 insertions(+), 12 deletions(-)

--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -167,7 +167,7 @@ void __native_set_fixmap(enum fixed_addr
 void native_set_fixmap(enum fixed_addresses idx,
 		       phys_addr_t phys, pgprot_t flags);
 
-#ifndef CONFIG_PARAVIRT
+#ifndef CONFIG_PARAVIRT_MMU
 static inline void __set_fixmap(enum fixed_addresses idx,
 				phys_addr_t phys, pgprot_t flags)
 {
--- a/arch/x86/include/asm/mmu_context.h
+++ b/arch/x86/include/asm/mmu_context.h
@@ -10,14 +10,14 @@
 #include <asm/pgalloc.h>
 #include <asm/tlbflush.h>
 #include <asm/paravirt.h>
-#ifndef CONFIG_PARAVIRT
+#ifndef CONFIG_PARAVIRT_MMU
 #include <asm-generic/mm_hooks.h>
 
 static inline void paravirt_activate_mm(struct mm_struct *prev,
 					struct mm_struct *next)
 {
 }
-#endif	/* !CONFIG_PARAVIRT */
+#endif	/* !CONFIG_PARAVIRT_MMU */
 
 /*
  * ldt_structs can be allocated, used, and freed, but they are never
--- a/arch/x86/include/asm/paravirt.h
+++ b/arch/x86/include/asm/paravirt.h
@@ -60,6 +60,7 @@ static inline void write_cr0(unsigned lo
 	PVOP_VCALL1(pv_cpu_ops.write_cr0, x);
 }
 
+#ifdef CONFIG_PARAVIRT_MMU
 static inline unsigned long read_cr2(void)
 {
 	return PVOP_CALL0(unsigned long, pv_mmu_ops.read_cr2);
@@ -79,6 +80,7 @@ static inline void write_cr3(unsigned lo
 {
 	PVOP_VCALL1(pv_mmu_ops.write_cr3, x);
 }
+#endif /* CONFIG_PARAVIRT_MMU */
 
 static inline unsigned long read_cr4(void)
 {
@@ -324,6 +326,7 @@ static inline void startup_ipi_hook(int
 }
 #endif
 
+#ifdef CONFIG_PARAVIRT_MMU
 static inline void paravirt_activate_mm(struct mm_struct *prev,
 					struct mm_struct *next)
 {
@@ -676,6 +679,7 @@ static inline void pmd_clear(pmd_t *pmdp
 	set_pmd(pmdp, __pmd(0));
 }
 #endif	/* CONFIG_X86_PAE */
+#endif  /* CONFIG_PARAVIRT_MMU */
 
 #define  __HAVE_ARCH_START_CONTEXT_SWITCH
 static inline void arch_start_context_switch(struct task_struct *prev)
@@ -688,6 +692,7 @@ static inline void arch_end_context_swit
 	PVOP_VCALL1(pv_cpu_ops.end_context_switch, next);
 }
 
+#ifdef CONFIG_PARAVIRT_MMU
 #define  __HAVE_ARCH_ENTER_LAZY_MMU_MODE
 static inline void arch_enter_lazy_mmu_mode(void)
 {
@@ -709,6 +714,7 @@ static inline void __set_fixmap(unsigned
 {
 	pv_mmu_ops.set_fixmap(idx, phys, flags);
 }
+#endif /* CONFIG_PARAVIRT_MMU */
 
 #if defined(CONFIG_SMP) && defined(CONFIG_PARAVIRT_SPINLOCKS)
 
@@ -964,8 +970,10 @@ extern void default_banner(void);
 		  call PARA_INDIRECT(pv_cpu_ops+PV_CPU_swapgs)		\
 		 )
 
+#ifdef CONFIG_PARAVIRT_MMU
 #define GET_CR2_INTO_RAX				\
 	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_read_cr2)
+#endif /* CONFIG_PARAVIRT_MMU */
 
 #define PARAVIRT_ADJUST_EXCEPTION_FRAME					\
 	PARA_SITE(PARA_PATCH(pv_irq_ops, PV_IRQ_adjust_exception_frame), \
--- a/arch/x86/include/asm/paravirt_types.h
+++ b/arch/x86/include/asm/paravirt_types.h
@@ -347,7 +347,9 @@ struct paravirt_patch_template {
 	struct pv_cpu_ops pv_cpu_ops;
 	struct pv_irq_ops pv_irq_ops;
 	struct pv_apic_ops pv_apic_ops;
+#ifdef CONFIG_PARAVIRT_MMU
 	struct pv_mmu_ops pv_mmu_ops;
+#endif /* CONFIG_PARAVIRT_MMU */
 	struct pv_lock_ops pv_lock_ops;
 };
 
--- a/arch/x86/include/asm/pgalloc.h
+++ b/arch/x86/include/asm/pgalloc.h
@@ -7,7 +7,7 @@
 
 static inline int  __paravirt_pgd_alloc(struct mm_struct *mm) { return 0; }
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #include <asm/paravirt.h>
 #else
 #define paravirt_pgd_alloc(mm)	__paravirt_pgd_alloc(mm)
--- a/arch/x86/include/asm/pgtable-3level_types.h
+++ b/arch/x86/include/asm/pgtable-3level_types.h
@@ -18,7 +18,7 @@ typedef union {
 } pte_t;
 #endif	/* !__ASSEMBLY__ */
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #define SHARED_KERNEL_PMD	(pv_info.shared_kernel_pmd)
 #else
 #define SHARED_KERNEL_PMD	1
--- a/arch/x86/include/asm/pgtable.h
+++ b/arch/x86/include/asm/pgtable.h
@@ -31,7 +31,7 @@ extern struct list_head pgd_list;
 
 extern struct mm_struct *pgd_page_get_mm(struct page *page);
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #include <asm/paravirt.h>
 #else  /* !CONFIG_PARAVIRT */
 #define set_pte(ptep, pte)		native_set_pte(ptep, pte)
--- a/arch/x86/include/asm/special_insns.h
+++ b/arch/x86/include/asm/special_insns.h
@@ -105,8 +105,9 @@ extern asmlinkage void native_load_gs_in
 
 #ifdef CONFIG_PARAVIRT
 #include <asm/paravirt.h>
-#else
+#endif
 
+#ifndef CONFIG_PARAVIRT
 static inline unsigned long read_cr0(void)
 {
 	return native_read_cr0();
@@ -116,7 +117,9 @@ static inline void write_cr0(unsigned lo
 {
 	native_write_cr0(x);
 }
+#endif /* CONFIG_PARAVIRT */
 
+#ifndef CONFIG_PARAVIRT_MMU
 static inline unsigned long read_cr2(void)
 {
 	return native_read_cr2();
@@ -136,7 +139,9 @@ static inline void write_cr3(unsigned lo
 {
 	native_write_cr3(x);
 }
+#endif /* CONFIG_PARAVIRT_MMU */
 
+#ifndef CONFIG_PARAVIRT
 static inline unsigned long read_cr4(void)
 {
 	return native_read_cr4();
--- a/arch/x86/include/asm/tlbflush.h
+++ b/arch/x86/include/asm/tlbflush.h
@@ -7,7 +7,7 @@
 #include <asm/processor.h>
 #include <asm/special_insns.h>
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #include <asm/paravirt.h>
 #else
 #define __flush_tlb() __native_flush_tlb()
@@ -198,7 +198,7 @@ static inline void reset_lazy_tlbstate(v
 
 #endif	/* SMP */
 
-#ifndef CONFIG_PARAVIRT
+#ifndef CONFIG_PARAVIRT_MMU
 #define flush_tlb_others(mask, mm, start, end)	\
 	native_flush_tlb_others(mask, mm, start, end)
 #endif
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -624,6 +624,15 @@ config PARAVIRT
 	  over full virtualization.  However, when run without a hypervisor
 	  the kernel is theoretically slower and slightly larger.
 
+config PARAVIRT_MMU
+	bool "PV MMU support"
+	---help---
+	  This option enables the paravirtualized MMU. In most (all?) cases
+	  it's pretty useless and shouldn't be used. It will only cost you
+	  performance, because it drags in pv-ops for memory management.
+
+	  If in doubt, say N.
+
 config PARAVIRT_DEBUG
 	bool "paravirt-ops debugging"
 	depends on PARAVIRT && DEBUG_KERNEL
--- a/arch/x86/kernel/head_64.S
+++ b/arch/x86/kernel/head_64.S
@@ -21,7 +21,7 @@
 #include <asm/percpu.h>
 #include <asm/nops.h>
 
-#ifdef CONFIG_PARAVIRT
+#ifdef CONFIG_PARAVIRT_MMU
 #include <asm/asm-offsets.h>
 #include <asm/paravirt.h>
 #define GET_CR2_INTO(reg) GET_CR2_INTO_RAX ; movq %rax, reg
--- a/arch/x86/kernel/paravirt.c
+++ b/arch/x86/kernel/paravirt.c
@@ -125,7 +125,9 @@ static void *get_call_destination(u8 typ
 		.pv_cpu_ops = pv_cpu_ops,
 		.pv_irq_ops = pv_irq_ops,
 		.pv_apic_ops = pv_apic_ops,
+#ifdef CONFIG_PARAVIRT_MMU
 		.pv_mmu_ops = pv_mmu_ops,
+#endif /* CONFIG_PARAVIRT_MMU */
 #ifdef CONFIG_PARAVIRT_SPINLOCKS
 		.pv_lock_ops = pv_lock_ops,
 #endif
@@ -180,6 +182,7 @@ unsigned paravirt_patch_insns(void *insn
 	return insn_len;
 }
 
+#ifdef CONFIG_PARAVIRT_MMU
 static void native_flush_tlb(void)
 {
 	__native_flush_tlb();
@@ -198,6 +201,7 @@ static void native_flush_tlb_single(unsi
 {
 	__native_flush_tlb_single(addr);
 }
+#endif /* CONFIG_PARAVIRT_MMU */
 
 struct static_key paravirt_steal_enabled;
 struct static_key paravirt_steal_rq_enabled;
@@ -403,6 +407,7 @@ struct pv_apic_ops pv_apic_ops = {
 #define PTE_IDENT	__PV_IS_CALLEE_SAVE(_paravirt_ident_64)
 #endif
 
+#ifdef CONFIG_PARAVIRT_MMU
 struct pv_mmu_ops pv_mmu_ops = {
 
 	.read_cr2 = native_read_cr2,
@@ -474,10 +479,11 @@ struct pv_mmu_ops pv_mmu_ops = {
 
 	.set_fixmap = native_set_fixmap,
 };
+EXPORT_SYMBOL    (pv_mmu_ops);
+#endif /* CONFIG_PARAVIRT_MMU */
 
 EXPORT_SYMBOL_GPL(pv_time_ops);
 EXPORT_SYMBOL    (pv_cpu_ops);
-EXPORT_SYMBOL    (pv_mmu_ops);
 EXPORT_SYMBOL_GPL(pv_apic_ops);
 EXPORT_SYMBOL_GPL(pv_info);
 EXPORT_SYMBOL    (pv_irq_ops);
--- a/arch/x86/kernel/paravirt_patch_32.c
+++ b/arch/x86/kernel/paravirt_patch_32.c
@@ -6,9 +6,11 @@ DEF_NATIVE(pv_irq_ops, restore_fl, "push
 DEF_NATIVE(pv_irq_ops, save_fl, "pushf; pop %eax");
 DEF_NATIVE(pv_cpu_ops, iret, "iret");
 DEF_NATIVE(pv_cpu_ops, irq_enable_sysexit, "sti; sysexit");
+#ifdef CONFIG_PARAVIRT_MMU
 DEF_NATIVE(pv_mmu_ops, read_cr2, "mov %cr2, %eax");
 DEF_NATIVE(pv_mmu_ops, write_cr3, "mov %eax, %cr3");
 DEF_NATIVE(pv_mmu_ops, read_cr3, "mov %cr3, %eax");
+#endif /* CONFIG_PARAVIRT_MMU */
 DEF_NATIVE(pv_cpu_ops, clts, "clts");
 DEF_NATIVE(pv_cpu_ops, read_tsc, "rdtsc");
 
@@ -42,9 +44,11 @@ unsigned native_patch(u8 type, u16 clobb
 		PATCH_SITE(pv_irq_ops, save_fl);
 		PATCH_SITE(pv_cpu_ops, iret);
 		PATCH_SITE(pv_cpu_ops, irq_enable_sysexit);
+#ifdef CONFIG_PARAVIRT_MMU
 		PATCH_SITE(pv_mmu_ops, read_cr2);
 		PATCH_SITE(pv_mmu_ops, read_cr3);
 		PATCH_SITE(pv_mmu_ops, write_cr3);
+#endif /* CONFIG_PARAVIRT_MMU */
 		PATCH_SITE(pv_cpu_ops, clts);
 		PATCH_SITE(pv_cpu_ops, read_tsc);
 
--- a/arch/x86/kernel/paravirt_patch_64.c
+++ b/arch/x86/kernel/paravirt_patch_64.c
@@ -6,10 +6,12 @@ DEF_NATIVE(pv_irq_ops, irq_disable, "cli
 DEF_NATIVE(pv_irq_ops, irq_enable, "sti");
 DEF_NATIVE(pv_irq_ops, restore_fl, "pushq %rdi; popfq");
 DEF_NATIVE(pv_irq_ops, save_fl, "pushfq; popq %rax");
+#ifdef CONFIG_PARAVIRT_MMU
 DEF_NATIVE(pv_mmu_ops, read_cr2, "movq %cr2, %rax");
 DEF_NATIVE(pv_mmu_ops, read_cr3, "movq %cr3, %rax");
 DEF_NATIVE(pv_mmu_ops, write_cr3, "movq %rdi, %cr3");
 DEF_NATIVE(pv_mmu_ops, flush_tlb_single, "invlpg (%rdi)");
+#endif /* CONFIG_PARAVIRT_MMU */
 DEF_NATIVE(pv_cpu_ops, clts, "clts");
 DEF_NATIVE(pv_cpu_ops, wbinvd, "wbinvd");
 
@@ -53,11 +55,13 @@ unsigned native_patch(u8 type, u16 clobb
 		PATCH_SITE(pv_cpu_ops, usergs_sysret32);
 		PATCH_SITE(pv_cpu_ops, usergs_sysret64);
 		PATCH_SITE(pv_cpu_ops, swapgs);
+#ifdef CONFIG_PARAVIRT_MMU
 		PATCH_SITE(pv_mmu_ops, read_cr2);
 		PATCH_SITE(pv_mmu_ops, read_cr3);
 		PATCH_SITE(pv_mmu_ops, write_cr3);
-		PATCH_SITE(pv_cpu_ops, clts);
 		PATCH_SITE(pv_mmu_ops, flush_tlb_single);
+#endif /* CONFIG_PARAVIRT_MMU */
+		PATCH_SITE(pv_cpu_ops, clts);
 		PATCH_SITE(pv_cpu_ops, wbinvd);
 
 	patch_site:
--- a/arch/x86/xen/Kconfig
+++ b/arch/x86/xen/Kconfig
@@ -6,6 +6,7 @@ config XEN
 	bool "Xen guest support"
 	depends on PARAVIRT
 	select PARAVIRT_CLOCK
+	select PARAVIRT_MMU
 	select XEN_HAVE_PVMMU
 	depends on X86_64 || (X86_32 && X86_PAE && !X86_VISWS)
 	depends on X86_TSC
