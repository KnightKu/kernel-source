From: Hannes Reinecke <hare@suse.de>
Date: Tue, 6 Mar 2018 11:37:12 +0100
Subject: [PATCH] nvme: only start KATO if the controller is live
Patch-Mainline: never, SLE12 SP3 specific fix
References: bsc#1083387

If the controller is not live there hardly is a point running
KATO, as chances are we won't be able to send any keep-alive
requests anyway.
Plus we don't have a good way of checking if a keep-alive request
is running, so keep-alive might be clashing with the reconnect
handling.
So better only start KATO if the controller is in state LIVE, and
check in the end io handling if we can send the next keep-alive
request.

Signed-off-by: Hannes Reinecke <hare@suse.com>
---
 drivers/nvme/host/core.c |  3 ++-
 drivers/nvme/host/fc.c   | 11 ++++++-----
 drivers/nvme/host/rdma.c | 11 ++++++-----
 3 files changed, 14 insertions(+), 11 deletions(-)

diff --git a/drivers/nvme/host/core.c b/drivers/nvme/host/core.c
index ddfa6787f956..8295913336fc 100644
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@ -528,7 +528,8 @@ static void nvme_keep_alive_end_io(struct request *rq, int error)
 		return;
 	}
 
-	schedule_delayed_work(&ctrl->ka_work, ctrl->kato * HZ);
+	if (ctrl->state == NVME_CTRL_LIVE)
+		schedule_delayed_work(&ctrl->ka_work, ctrl->kato * HZ);
 }
 
 static int nvme_keep_alive(struct nvme_ctrl *ctrl)
diff --git a/drivers/nvme/host/fc.c b/drivers/nvme/host/fc.c
index 1a7d9d048506..d46942828a34 100644
--- a/drivers/nvme/host/fc.c
+++ b/drivers/nvme/host/fc.c
@@ -2735,8 +2735,6 @@ nvme_fc_create_association(struct nvme_fc_ctrl *ctrl)
 		goto out_disconnect_admin_queue;
 	}
 
-	nvme_start_keep_alive(&ctrl->ctrl);
-
 	/* FC-NVME supports normal SGL Data Block Descriptors */
 
 	if (opts->queue_size > ctrl->ctrl.maxcmd) {
@@ -2767,6 +2765,8 @@ nvme_fc_create_association(struct nvme_fc_ctrl *ctrl)
 
 	changed = nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_LIVE);
 
+	nvme_start_keep_alive(&ctrl->ctrl);
+
 	ctrl->ctrl.opts->nr_reconnects = 0;
 
 	if (changed && ctrl->queue_count > 1) {
@@ -2779,7 +2779,6 @@ nvme_fc_create_association(struct nvme_fc_ctrl *ctrl)
 
 out_term_aen_ops:
 	nvme_fc_term_aen_ops(ctrl);
-	nvme_stop_keep_alive(&ctrl->ctrl);
 out_disconnect_admin_queue:
 	/* send a Disconnect(association) LS to fc-nvme target */
 	nvme_fc_xmt_disconnect_assoc(ctrl);
@@ -2804,8 +2803,6 @@ nvme_fc_delete_association(struct nvme_fc_ctrl *ctrl)
 {
 	unsigned long flags;
 
-	nvme_stop_keep_alive(&ctrl->ctrl);
-
 	if (!ctrl->assoc_active)
 		return;
 	ctrl->assoc_active = false;
@@ -2904,6 +2901,8 @@ nvme_fc_delete_ctrl_work(struct work_struct *work)
 	 */
 	nvme_fc_delete_association(ctrl);
 
+	nvme_stop_keep_alive(&ctrl->ctrl);
+
 	/* resume the io queues so that things will fail */
 	nvme_start_queues(&ctrl->ctrl);
 
@@ -3020,6 +3019,8 @@ nvme_fc_reset_ctrl_work(struct work_struct *work)
 		return;
 	}
 
+	nvme_stop_keep_alive(&ctrl->ctrl);
+
 	if (ctrl->rport->remoteport.port_state == FC_OBJSTATE_ONLINE)
 		ret = nvme_fc_create_association(ctrl);
 	else
diff --git a/drivers/nvme/host/rdma.c b/drivers/nvme/host/rdma.c
index 1ea24f2e00d7..fa77638a0ff5 100644
--- a/drivers/nvme/host/rdma.c
+++ b/drivers/nvme/host/rdma.c
@@ -769,8 +769,6 @@ static void nvme_rdma_reconnect_ctrl_work(struct work_struct *work)
 	if (ret)
 		goto requeue;
 
-	nvme_start_keep_alive(&ctrl->ctrl);
-
 	if (ctrl->queue_count > 1) {
 		ret = nvme_rdma_init_io_queues(ctrl);
 		if (ret)
@@ -788,6 +786,8 @@ static void nvme_rdma_reconnect_ctrl_work(struct work_struct *work)
 	WARN_ON_ONCE(!changed);
 	ctrl->ctrl.opts->nr_reconnects = 0;
 
+	nvme_start_keep_alive(&ctrl->ctrl);
+
 	if (ctrl->queue_count > 1) {
 		nvme_queue_scan(&ctrl->ctrl);
 		nvme_queue_async_events(&ctrl->ctrl);
@@ -1624,8 +1624,6 @@ static int nvme_rdma_configure_admin_queue(struct nvme_rdma_ctrl *ctrl)
 	if (error)
 		goto out_cleanup_queue;
 
-	nvme_start_keep_alive(&ctrl->ctrl);
-
 	return 0;
 
 out_cleanup_queue:
@@ -1759,6 +1757,8 @@ static void nvme_rdma_reset_ctrl_work(struct work_struct *work)
 	changed = nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_LIVE);
 	WARN_ON_ONCE(!changed);
 
+	nvme_start_keep_alive(&ctrl->ctrl);
+
 	if (ctrl->queue_count > 1) {
 		nvme_start_queues(&ctrl->ctrl);
 		nvme_queue_scan(&ctrl->ctrl);
@@ -2060,6 +2060,8 @@ static struct nvme_ctrl *nvme_rdma_create_ctrl(struct device *dev,
 	changed = nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_LIVE);
 	WARN_ON_ONCE(!changed);
 
+	nvme_start_keep_alive(&ctrl->ctrl);
+
 	dev_info(ctrl->ctrl.device, "new ctrl: NQN \"%s\", addr %pISp\n",
 		ctrl->ctrl.opts->subsysnqn, &ctrl->addr);
 
@@ -2077,7 +2079,6 @@ static struct nvme_ctrl *nvme_rdma_create_ctrl(struct device *dev,
 	return &ctrl->ctrl;
 
 out_remove_admin_queue:
-	nvme_stop_keep_alive(&ctrl->ctrl);
 	nvme_rdma_destroy_admin_queue(ctrl);
 out_kfree_queues:
 	kfree(ctrl->queues);
-- 
2.12.3

