From: Nicolai Stange <nstange@suse.de>
Subject: ppc64le: reliable stacktrace: fix stacktrace for idle tasks
Patch-mainline: Never, temporary fix to get things going here
References: bsc#1087458

The current ppc64le save_stack_trace_tsk_reliable() implementation
always reports an unreliable stacktrace for the swapper tasks and thus,
prevents a live patch transition from finishing under load.

The reason is that the idle tasks have a slightly different stack
layout at their top.

Fix this by checking for PF_IDLE and handle those tasks as appropriate.

Note that this is a temporary fix for
suse-commit a4da14cfd7a8 ("On ppc64le we HAVE_RELIABLE_STACKTRACE")
which is likely to get reworked anyway.

Signed-off-by: Nicolai Stange <nstange@suse.de>

---
 arch/powerpc/kernel/stacktrace.c |   41 +++++++++++++++++++++++++++++++--------
 1 file changed, 33 insertions(+), 8 deletions(-)

--- a/arch/powerpc/kernel/stacktrace.c
+++ b/arch/powerpc/kernel/stacktrace.c
@@ -87,6 +87,7 @@ save_stack_trace_tsk_reliable(struct tas
 {
 	unsigned long sp;
 	unsigned long stack_page = (unsigned long)task_stack_page(tsk);
+	unsigned long stack_end;
 
 	/* The last frame (unwinding first) may not yet have saved
 	 * its LR onto the stack.
@@ -98,9 +99,35 @@ save_stack_trace_tsk_reliable(struct tas
 	else
 		sp = tsk->thread.ksp;
 
-	if (sp < stack_page + sizeof(struct thread_struct)
-	    || sp > stack_page + THREAD_SIZE - STACK_FRAME_OVERHEAD)
+	stack_end = stack_page + THREAD_SIZE;
+	if (!is_idle_task(tsk)) {
+		/*
+		 * For user tasks, this is the SP value loaded on
+		 * kernel entry, see "PACAKSAVE(r13)" in _switch() and
+		 * system_call_common()/EXCEPTION_PROLOG_COMMON().
+		 *
+		 * Likewise for non-swapper kernel threads,
+		 * this also happens to be the top of the stack
+		 * as setup by copy_thread().
+		 *
+		 * Note that stack backlinks are not properly setup by
+		 * copy_thread() and thus, a forked task() will have
+		 * an unreliable stack trace until it's been
+		 * _switch()'ed to for the first time.
+		 */
+		stack_end -= STACK_FRAME_OVERHEAD + sizeof(struct pt_regs);
+	} else {
+		/*
+		 * idle tasks have a custom stack layout,
+		 * c.f. cpu_idle_thread_init().
+		 */
+		stack_end -= STACK_FRAME_OVERHEAD;
+	}
+
+	if (sp < stack_page + sizeof(struct thread_struct) ||
+	    sp > stack_end - STACK_FRAME_MIN_SIZE) {
 		return 1;
+	}
 
 	for (;;) {
 		unsigned long *stack = (unsigned long *) sp;
@@ -115,8 +142,10 @@ save_stack_trace_tsk_reliable(struct tas
 		if (newsp <= sp)
 			return 1;
 
-		if (newsp >= stack_page + THREAD_SIZE)
+		if (newsp != stack_end &&
+		    newsp > stack_end - STACK_FRAME_MIN_SIZE) {
 			return 1; /* invalid backlink, too far up. */
+		}
 
 		/* Examine the saved LR: it must point into kernel code. */
 		ip = stack[STACK_FRAME_LR_SAVE];
@@ -137,11 +166,7 @@ save_stack_trace_tsk_reliable(struct tas
 		else
 			trace->skip--;
 
-		/* SP value loaded on kernel entry, see "PACAKSAVE(r13)" in
-		 * _switch() and system_call_common()
-		 */
-		if (newsp == stack_page + THREAD_SIZE - /* SWITCH_FRAME_SIZE */
-		    (STACK_FRAME_OVERHEAD + sizeof(struct pt_regs)))
+		if (newsp == stack_end)
 			break;
 
 		if (trace->nr_entries >= trace->max_entries)
