From: Jiri Kosina <jkosina@suse.cz>
Date: Sun, 15 Sep 2013 21:36:47 +0200
Subject: kgr: initial code
Patch-mainline: submitted for review
References: fate#313296

Provide initial implementation. We are now able to do ftrace-based
runtime patching of the kernel code.

In addition to that, we will provide a kgr_patcher module in the next
patch to test the functionality.

Note that the per-process flag dismisses in later patches where it is
converted to a single bit in the thread_info.

Limitation: kGraft is x86_64 only yet

Additional squashes to this patch:
jk: add missing Kconfig.kgr
jk: fixup a header bug
jk: cleanup comments
js: port to new mcount infrastructure
js: order includes
js: fix for non-KGR (prototype and Kconfig fixes)
js: fix potential lock imbalance in kgr_patch_code
js: use insn helper for jmp generation
js: add \n to a printk
jk: externally_visible attribute warning fix
jk: symbol lookup failure handling
jk: fix race between patching and setting a flag (thanks to bpetkov)
js: add more sanity checking
js: handle missing kallsyms gracefully
js: use correct name, not alias
js: fix index in cleanup path
js: clear kgr_in_progress for all syscall paths
js: cleanup
js: do the checking in the process context
js: call kgr_mark_processes outside loop and locks
jk: convert from raw patching to ftrace API
jk: depend on regs-saving ftrace
js: make kgr_init an init_call
js: use correct offset for stub
js: use pr_debug
js: use IS_ENABLED
js: fix potential memory leak
js: change names from kgr -> kGraft
js: fix error handling and return values
js: use bitops to be atomic
jk: helpers for task's kgr_in_progress
js: remove copies of stubs, have only a single instance
js: fix print loglevels and remove a stale comment
js: once more ^^^^^^^^^
js: rename kgr_start_patching to kgr_patch_kernel
js: massive cleanup and documentation
js: handle patch module refcount internally
js: remove the need of attribute used
js: make all the structs self-contained
js: add some comments
js: remove filter properly
pm: better name for kgr_for_each_patch_fun
js: move the kgr_ftrace a bit upper

Signed-off-by: Jiri Kosina <jkosina@suse.cz>
Signed-off-by: Jiri Slaby <jslaby@suse.cz>
Signed-off-by: Petr Mladek <pmladek@suse.cz>
Cc: Steven Rostedt <rostedt@goodmis.org>
Cc: Frederic Weisbecker <fweisbec@gmail.com>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Andi Kleen <andi@firstfloor.org>
---
 arch/x86/Kconfig                   |    2 
 arch/x86/include/asm/kgraft.h      |   27 ++
 arch/x86/include/asm/thread_info.h |    1 
 arch/x86/kernel/asm-offsets.c      |    1 
 arch/x86/kernel/entry_64.S         |    3 
 include/linux/kgraft.h             |   87 ++++++++
 kernel/Kconfig.kgraft              |    7 
 kernel/Makefile                    |    1 
 kernel/kgraft.c                    |  361 +++++++++++++++++++++++++++++++++++++
 9 files changed, 490 insertions(+)
 create mode 100644 arch/x86/include/asm/kgraft.h
 create mode 100644 include/linux/kgraft.h
 create mode 100644 kernel/Kconfig.kgraft
 create mode 100644 kernel/kgraft.c

--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -125,6 +125,7 @@ config X86
 	select RTC_LIB
 	select HAVE_DEBUG_STACKOVERFLOW
 	select ARCH_SUPPORTS_ATOMIC_RMW
+	select HAVE_KGRAFT
 
 config INSTRUCTION_DECODER
 	def_bool y
@@ -265,6 +266,7 @@ config ARCH_SUPPORTS_UPROBES
 
 source "init/Kconfig"
 source "kernel/Kconfig.freezer"
+source "kernel/Kconfig.kgraft"
 
 menu "Processor type and features"
 
--- /dev/null
+++ b/arch/x86/include/asm/kgraft.h
@@ -0,0 +1,27 @@
+/*
+ * kGraft Online Kernel Patching
+ *
+ *  Copyright (c) 2013-2014 SUSE
+ *   Authors: Jiri Kosina
+ *	      Vojtech Pavlik
+ *	      Jiri Slaby
+ */
+
+/*
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option)
+ * any later version.
+ */
+
+#ifndef ASM_KGR_H
+#define ASM_KGR_H
+
+#include <asm/ptrace.h>
+
+static inline void kgr_set_regs_ip(struct pt_regs *regs, unsigned long ip)
+{
+	regs->ip = ip;
+}
+
+#endif
--- a/arch/x86/include/asm/thread_info.h
+++ b/arch/x86/include/asm/thread_info.h
@@ -41,6 +41,7 @@ struct thread_info {
 #endif
 	unsigned int		sig_on_uaccess_error:1;
 	unsigned int		uaccess_err:1;	/* uaccess failed */
+	unsigned long		kgr_in_progress;
 };
 
 #define INIT_THREAD_INFO(tsk)			\
--- a/arch/x86/kernel/asm-offsets.c
+++ b/arch/x86/kernel/asm-offsets.c
@@ -33,6 +33,7 @@ void common(void) {
 	OFFSET(TI_status, thread_info, status);
 	OFFSET(TI_addr_limit, thread_info, addr_limit);
 	OFFSET(TI_preempt_count, thread_info, preempt_count);
+	OFFSET(TI_kgr_in_progress, thread_info, kgr_in_progress);
 
 	BLANK();
 	OFFSET(crypto_tfm_ctx_offset, crypto_tfm, __crt_ctx);
--- a/arch/x86/kernel/entry_64.S
+++ b/arch/x86/kernel/entry_64.S
@@ -616,6 +616,7 @@ GLOBAL(system_call_after_swapgs)
 	movq  %rax,ORIG_RAX-ARGOFFSET(%rsp)
 	movq  %rcx,RIP-ARGOFFSET(%rsp)
 	CFI_REL_OFFSET rip,RIP-ARGOFFSET
+	movq $0, TI_kgr_in_progress+THREAD_INFO(%rsp,RIP-ARGOFFSET)
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags+THREAD_INFO(%rsp,RIP-ARGOFFSET)
 	jnz tracesys
 system_call_fastpath:
@@ -640,6 +641,7 @@ sysret_check:
 	LOCKDEP_SYS_EXIT
 	DISABLE_INTERRUPTS(CLBR_NONE)
 	TRACE_IRQS_OFF
+	movq $0, TI_kgr_in_progress+THREAD_INFO(%rsp,RIP-ARGOFFSET)
 	movl TI_flags+THREAD_INFO(%rsp,RIP-ARGOFFSET),%edx
 	andl %edi,%edx
 	jnz  sysret_careful
@@ -762,6 +764,7 @@ GLOBAL(int_ret_from_sys_call)
 GLOBAL(int_with_check)
 	LOCKDEP_SYS_EXIT_IRQ
 	GET_THREAD_INFO(%rcx)
+	movq $0, TI_kgr_in_progress(%rcx)
 	movl TI_flags(%rcx),%edx
 	andl %edi,%edx
 	jnz   int_careful
--- /dev/null
+++ b/include/linux/kgraft.h
@@ -0,0 +1,87 @@
+/*
+ * kGraft Online Kernel Patching
+ *
+ *  Copyright (c) 2013-2014 SUSE
+ *   Authors: Jiri Kosina
+ *	      Vojtech Pavlik
+ *	      Jiri Slaby
+ */
+
+/*
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option)
+ * any later version.
+ */
+
+#ifndef LINUX_KGR_H
+#define LINUX_KGR_H
+
+#include <linux/bitops.h>
+#include <linux/ftrace.h>
+#include <linux/sched.h>
+
+#if IS_ENABLED(CONFIG_KGRAFT)
+
+#include <asm/kgraft.h>
+
+#define KGR_TIMEOUT 30
+
+/**
+ * struct kgr_patch_fun -- state of a single function in a kGraft patch
+ *
+ * @name: function to patch
+ * @new_fun: function with the new body
+ * @loc_old: cache of @name's fentry
+ * @loc_new: cache of @new_name's fentry
+ * @ftrace_ops_slow: ftrace ops for slow (temporary) stub
+ * @ftrace_ops_fast: ftrace ops for fast () stub
+ */
+struct kgr_patch_fun {
+	const char *name;
+	void *new_fun;
+
+	unsigned long loc_old;
+	unsigned long loc_new;
+
+	struct ftrace_ops ftrace_ops_slow;
+	struct ftrace_ops ftrace_ops_fast;
+};
+
+/**
+ * struct kgr_patch -- a kGraft patch
+ *
+ * @owner: module to refcount on patching
+ * @patches: array of @kgr_patch_fun structures
+ */
+struct kgr_patch {
+	/* a patch shall set these */
+	struct module *owner;
+	struct kgr_patch_fun patches[];
+};
+
+#define kgr_for_each_patch_fun(p, pf)	\
+	for (pf = p->patches; pf->name; pf++)
+
+#define KGR_PATCH(_name, _new_function)		{			\
+		.name = #_name,						\
+		.new_fun = _new_function,				\
+	}
+#define KGR_PATCH_END				{ }
+
+extern int kgr_patch_kernel(struct kgr_patch *);
+
+static inline void kgr_mark_task_in_progress(struct task_struct *p)
+{
+	/* This is replaced by thread_flag later. */
+	set_bit(0, &task_thread_info(p)->kgr_in_progress);
+}
+
+static inline bool kgr_task_in_progress(struct task_struct *p)
+{
+	return test_bit(0, &task_thread_info(p)->kgr_in_progress);
+}
+
+#endif /* IS_ENABLED(CONFIG_KGRAFT) */
+
+#endif /* LINUX_KGR_H */
--- /dev/null
+++ b/kernel/Kconfig.kgraft
@@ -0,0 +1,7 @@
+config HAVE_KGRAFT
+	bool
+
+config KGRAFT
+	bool "kGraft infrastructure"
+	depends on DYNAMIC_FTRACE_WITH_REGS
+	depends on HAVE_KGRAFT
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -25,6 +25,7 @@ obj-y += printk/
 obj-y += cpu/
 obj-y += irq/
 
+obj-$(CONFIG_KGRAFT) += kgraft.o
 obj-$(CONFIG_CHECKPOINT_RESTORE) += kcmp.o
 obj-$(CONFIG_FREEZER) += freezer.o
 obj-$(CONFIG_PROFILING) += profile.o
--- /dev/null
+++ b/kernel/kgraft.c
@@ -0,0 +1,361 @@
+/*
+ * kGraft Online Kernel Patching
+ *
+ *  Copyright (c) 2013-2014 SUSE
+ *   Authors: Jiri Kosina
+ *	      Vojtech Pavlik
+ *	      Jiri Slaby
+ */
+
+/*
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2 of the License, or (at your option)
+ * any later version.
+ */
+
+#include <linux/ftrace.h>
+#include <linux/kallsyms.h>
+#include <linux/kgraft.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/sort.h>
+#include <linux/spinlock.h>
+#include <linux/types.h>
+#include <linux/workqueue.h>
+
+static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final);
+static void kgr_work_fn(struct work_struct *work);
+
+static struct workqueue_struct *kgr_wq;
+static DECLARE_DELAYED_WORK(kgr_work, kgr_work_fn);
+static DEFINE_MUTEX(kgr_in_progress_lock);
+static bool kgr_in_progress;
+static bool kgr_initialized;
+static struct kgr_patch *kgr_patch;
+
+/*
+ * The stub needs to modify the RIP value stored in struct pt_regs
+ * so that ftrace redirects the execution properly.
+ */
+static void kgr_stub_fast(unsigned long ip, unsigned long parent_ip,
+		struct ftrace_ops *ops, struct pt_regs *regs)
+{
+	struct kgr_patch_fun *p = ops->private;
+
+	pr_debug("kgr: fast stub: calling new code at %lx\n", p->loc_new);
+	kgr_set_regs_ip(regs, p->loc_new);
+}
+
+static void kgr_stub_slow(unsigned long ip, unsigned long parent_ip,
+		struct ftrace_ops *ops, struct pt_regs *regs)
+{
+	struct kgr_patch_fun *p = ops->private;
+	bool go_old = kgr_task_in_progress(current) && current->mm;
+
+	if (go_old) {
+		pr_debug("kgr: slow stub: calling old code at %lx\n",
+				p->loc_old);
+		kgr_set_regs_ip(regs, p->loc_old + MCOUNT_INSN_SIZE);
+	} else {
+		pr_debug("kgr: slow stub: calling new code at %lx\n",
+				p->loc_new);
+		kgr_set_regs_ip(regs, p->loc_new);
+	}
+}
+
+static int kgr_ftrace_enable(struct kgr_patch_fun *pf, struct ftrace_ops *fops)
+{
+	int ret;
+
+	ret = ftrace_set_filter_ip(fops, pf->loc_old, 0, 0);
+	if (ret)
+		return ret;
+
+	ret = register_ftrace_function(fops);
+	if (ret)
+		ftrace_set_filter_ip(fops, pf->loc_old, 1, 0);
+
+	return ret;
+}
+
+static int kgr_ftrace_disable(struct kgr_patch_fun *pf, struct ftrace_ops *fops)
+{
+	int ret;
+
+	ret = unregister_ftrace_function(fops);
+	if (ret)
+		return ret;
+
+	ret = ftrace_set_filter_ip(fops, pf->loc_old, 1, 0);
+	if (ret)
+		register_ftrace_function(fops);
+
+	return ret;
+}
+
+static bool kgr_still_patching(void)
+{
+	struct task_struct *p;
+	bool failed = false;
+
+	read_lock(&tasklist_lock);
+	for_each_process(p) {
+		/*
+		 * TODO
+		 *   kernel thread codepaths not supported and silently ignored
+		 */
+		if (kgr_task_in_progress(p) && p->mm) {
+			pr_info("pid %d (%s) still in kernel after timeout\n",
+					p->pid, p->comm);
+			failed = true;
+		}
+	}
+	read_unlock(&tasklist_lock);
+	return failed;
+}
+
+static void kgr_finalize(void)
+{
+	struct kgr_patch_fun *patch_fun;
+
+	kgr_for_each_patch_fun(kgr_patch, patch_fun) {
+		int ret = kgr_patch_code(patch_fun, true);
+
+		if (ret < 0)
+			pr_err("kgr: finalize for %s failed, trying to continue\n",
+					patch_fun->name);
+	}
+
+	mutex_lock(&kgr_in_progress_lock);
+	kgr_in_progress = false;
+	mutex_unlock(&kgr_in_progress_lock);
+}
+
+static void kgr_work_fn(struct work_struct *work)
+{
+	if (kgr_still_patching()) {
+		pr_info("kgr failed after timeout (%d), still in degraded mode\n",
+			KGR_TIMEOUT);
+		/* recheck again later */
+		queue_delayed_work(kgr_wq, &kgr_work, KGR_TIMEOUT * HZ);
+		return;
+	}
+
+	/*
+	 * victory, patching finished, put everything back in shape
+	 * with as less performance impact as possible again
+	 */
+	pr_info("kgr succeeded\n");
+	kgr_finalize();
+}
+
+static void kgr_mark_processes(void)
+{
+	struct task_struct *p;
+
+	read_lock(&tasklist_lock);
+	for_each_process(p)
+		kgr_mark_task_in_progress(p);
+	read_unlock(&tasklist_lock);
+}
+
+static unsigned long kgr_get_fentry_loc(const char *f_name)
+{
+	unsigned long orig_addr, fentry_loc;
+	const char *check_name;
+	char check_buf[KSYM_SYMBOL_LEN];
+
+	orig_addr = kallsyms_lookup_name(f_name);
+	if (!orig_addr) {
+		pr_err("kgr: function %s not resolved\n", f_name);
+		return -ENOENT;
+	}
+
+	fentry_loc = ftrace_function_to_fentry(orig_addr);
+	if (!fentry_loc) {
+		pr_err("kgr: fentry_loc not properly resolved\n");
+		return -ENXIO;
+	}
+
+	check_name = kallsyms_lookup(fentry_loc, NULL, NULL, NULL, check_buf);
+	if (strcmp(check_name, f_name)) {
+		pr_err("kgr: we got out of bounds the intended function (%s -> %s)\n",
+				f_name, check_name);
+		return -EINVAL;
+	}
+
+	return fentry_loc;
+}
+
+static int kgr_init_ftrace_ops(struct kgr_patch_fun *patch_fun)
+{
+	struct ftrace_ops *fops;
+	unsigned long fentry_loc;
+
+	/*
+	 * Initialize the ftrace_ops->private with pointers to the fentry
+	 * sites of both old and new functions. This is used as a
+	 * redirection target in the stubs.
+	 */
+
+	fentry_loc = ftrace_function_to_fentry(
+			((unsigned long)patch_fun->new_fun));
+	if (!fentry_loc) {
+		pr_err("kgr: fentry_loc not properly resolved\n");
+		return -ENXIO;
+	}
+
+	pr_debug("kgr: storing %lx to loc_new for %pf\n",
+			fentry_loc, patch_fun->new_fun);
+	patch_fun->loc_new = fentry_loc;
+
+	fentry_loc = kgr_get_fentry_loc(patch_fun->name);
+	if (IS_ERR_VALUE(fentry_loc))
+		return fentry_loc;
+
+	pr_debug("kgr: storing %lx to loc_old for %s\n",
+			fentry_loc, patch_fun->name);
+	patch_fun->loc_old = fentry_loc;
+
+	fops = &patch_fun->ftrace_ops_fast;
+	fops->private = patch_fun;
+	fops->func = kgr_stub_fast;
+	fops->flags = FTRACE_OPS_FL_SAVE_REGS;
+
+	fops = &patch_fun->ftrace_ops_slow;
+	fops->private = patch_fun;
+	fops->func = kgr_stub_slow;
+	fops->flags = FTRACE_OPS_FL_SAVE_REGS;
+
+	return 0;
+}
+
+static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final)
+{
+	struct ftrace_ops *new_ops;
+	int err;
+
+	/* Choose between slow and fast stub */
+	if (!final) {
+		err = kgr_init_ftrace_ops(patch_fun);
+		if (err)
+			return err;
+		pr_debug("kgr: patching %s to slow stub\n", patch_fun->name);
+		new_ops = &patch_fun->ftrace_ops_slow;
+	} else {
+		pr_debug("kgr: patching %s to fast stub\n", patch_fun->name);
+		new_ops = &patch_fun->ftrace_ops_fast;
+	}
+
+	/* Flip the switch */
+	err = kgr_ftrace_enable(patch_fun, new_ops);
+	if (err) {
+		pr_err("kgr: cannot enable ftrace function for %lx (%s)\n",
+				patch_fun->loc_old, patch_fun->name);
+		return err;
+	}
+
+	/*
+	 * Get rid of the slow stub. Having two stubs in the interim is fine,
+	 * the last one always "wins", as it'll be dragged earlier from the
+	 * ftrace hashtable
+	 */
+	if (final) {
+		err = kgr_ftrace_disable(patch_fun,
+				&patch_fun->ftrace_ops_slow);
+		if (err) {
+			pr_warning("kgr: disabling ftrace function for %s failed with %d\n",
+					patch_fun->name, err);
+			/* don't fail: we are only slower */
+		}
+	}
+	pr_debug("kgr: redirection for %s done\n", patch_fun->name);
+
+	return 0;
+}
+
+/**
+ * kgr_patch_kernel -- the entry for a kgraft patch
+ * @patch: patch to be applied
+ *
+ * Start patching of code that is neither running in IRQ context nor
+ * kernel thread.
+ */
+int kgr_patch_kernel(struct kgr_patch *patch)
+{
+	struct kgr_patch_fun *patch_fun;
+	int ret;
+
+	if (!kgr_initialized) {
+		pr_err("kgr: can't patch, not initialized\n");
+		return -EINVAL;
+	}
+
+	if (!try_module_get(patch->owner)) {
+		pr_err("kgr: can't increase patch module refcount\n");
+		return -EBUSY;
+	}
+
+	mutex_lock(&kgr_in_progress_lock);
+	if (kgr_in_progress) {
+		pr_err("kgr: can't patch, another patching not yet finalized\n");
+		ret = -EAGAIN;
+		goto err_unlock;
+	}
+
+	kgr_for_each_patch_fun(patch, patch_fun) {
+		ret = kgr_patch_code(patch_fun, false);
+		/*
+		 * In case any of the symbol resolutions in the set
+		 * has failed, patch all the previously replaced fentry
+		 * callsites back to nops and fail with grace
+		 */
+		if (ret < 0) {
+			for (patch_fun--; patch_fun >= patch->patches;
+					patch_fun--)
+				kgr_ftrace_disable(patch_fun,
+						&patch_fun->ftrace_ops_slow);
+			goto err_unlock;
+		}
+	}
+	kgr_in_progress = true;
+	kgr_patch = patch;
+	mutex_unlock(&kgr_in_progress_lock);
+
+	kgr_mark_processes();
+
+	/*
+	 * give everyone time to exit kernel, and check after a while
+	 */
+	queue_delayed_work(kgr_wq, &kgr_work, KGR_TIMEOUT * HZ);
+
+	return 0;
+err_unlock:
+	mutex_unlock(&kgr_in_progress_lock);
+	module_put(patch->owner);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(kgr_patch_kernel);
+
+static int __init kgr_init(void)
+{
+	if (ftrace_is_dead()) {
+		pr_warn("kgr: enabled, but no fentry locations found ... aborting\n");
+		return -ENODEV;
+	}
+
+	kgr_wq = create_singlethread_workqueue("kgraft");
+	if (!kgr_wq) {
+		pr_err("kgr: cannot allocate a work queue, aborting!\n");
+		return -ENOMEM;
+	}
+
+	kgr_initialized = true;
+	pr_info("kgr: successfully initialized\n");
+
+	return 0;
+}
+module_init(kgr_init);
