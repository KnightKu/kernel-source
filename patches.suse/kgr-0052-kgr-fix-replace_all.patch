From: Miroslav Benes <mbenes@suse.cz>
Date: Mon, 29 Dec 2014 17:02:01 +0100
Subject: kgr: fix replace_all
Patch-mainline: submitted for review
References: fate#313296 fate#318214

Current implementation of replace_all functionality does not fully allow
to go back in the patch series. The situation can be illustrated in the
following way.

Kernel contains functions A and B. Patch1 patches both functions (new
versions are called A1 and B1). Patch2 (replace_all) only function A
(A2). If A calls B there is a race window during application of Patch2.
A2 can call B1, which is wrong. It should call the original B. It is
caused by postponed revert of B1 after finalization of A2.

Also two-step finalization of the replace_all patch is wrong as it leads
to bugs. First the "forward" patch_funs of the patch (A) are finalized.
Then reverted functions (B) have to be finalized after another
kgr_modify_kernel call. This second step however includes also another
finalization of the forward functions which is not possible. Finally,
refs in kgr_patch structures are not correct.

This fix preserves the original idea of the replace_all process, but
implements it earlier in kgr_modify_kernel.

* First, we walk through previous patches in kgr_patches list and their
  functions patch_fun. If patch_fun is not present in replace_all patch
  it is reverted (slow revert). Nothing is done in the opposite case.
* Then all patches for functions in the replace_all patch are applied.
  There is no race window, because we are protected by immutable flag.

Finalization is very similar.

* First, all patch_funs from the replace_all are finalized in the
  ordinary way.
* Then we can finalize the reverted patch_funs from previous patches.
  Non reverted patch_funs are pushed right to the KGR_PATCH_REVERTED
  state ("fast revert").
* Next all patches from kgr_patches list can be removed, because they
  are no longer used (and fast stubs are already applied).

Apart from these changes consistency with stacking of patches has to be
preserved.

* In case of reverted patch_funs (i.e. not present in replace_all patch,
  e.g. B1) ftrace needs to be update only for last patch_funs for each
  function (i.e.  for B1 and not some hypothetical B0 applied
  beforehand).  This applies to APPLIED and REVERT_SLOW states in
  kgr_patch_code.
* In slow stub, calls to reverted patch_funs in new universe have to be
  redirected to the original functions. I.e. if we have series of
  stacked patch_funs B0->B1 over the original B, calls to B must really
  call B and not B0 in the new universe (however it has to call B1 in
  the old one). Instead of editing the slow stub we change loc_old to
  loc_name before the actual revert is started.
* After finalization loc_old of forward patch_funs have to be switched
  to loc_name to prepare correct revert of the replace_all patch (if
  required). It cannot be done during initialization of ftrace_ops
  because we need correct loc_old (in terms of stacking) for the slow
  stub and old universes.

Finally, delayed loading of modules has to be updated. Some module with
to be patched functions can be loaded while the replace_all patch is
being applied. We need to get to the same state as if the module had
been loaded before the replace_all patch came.

References: FATE#318214
Signed-off-by: Miroslav Benes <mbenes@suse.cz>
Signed-off-by: Jiri Slaby <jslaby@suse.cz>
---
 include/linux/kgraft.h |   2 +-
 kernel/kgraft.c        | 265 +++++++++++++++++++++++++++++++------------------
 kernel/kgraft_files.c  |   2 +-
 3 files changed, 171 insertions(+), 98 deletions(-)

diff --git a/include/linux/kgraft.h b/include/linux/kgraft.h
index 271086b7e132..6bfed8cc8575 100644
--- a/include/linux/kgraft.h
+++ b/include/linux/kgraft.h
@@ -115,7 +115,7 @@ extern int kgr_patch_kernel(struct kgr_patch *);
 extern void kgr_patch_remove(struct kgr_patch *);
 
 extern void kgr_unmark_processes(void);
-extern int kgr_modify_kernel(struct kgr_patch *patch, bool revert, bool force);
+extern int kgr_modify_kernel(struct kgr_patch *patch, bool revert);
 extern void kgr_module_init(const struct module *mod);
 extern int kgr_patch_dir_add(struct kgr_patch *patch);
 extern void kgr_patch_dir_del(struct kgr_patch *patch);
diff --git a/kernel/kgraft.c b/kernel/kgraft.c
index e4e5f1939371..d8706b74a093 100644
--- a/kernel/kgraft.c
+++ b/kernel/kgraft.c
@@ -30,14 +30,13 @@
 #include <linux/workqueue.h>
 
 static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final,
-		bool revert);
+		bool revert, bool replace_revert);
 static void kgr_work_fn(struct work_struct *work);
 
 static struct workqueue_struct *kgr_wq;
 static DECLARE_DELAYED_WORK(kgr_work, kgr_work_fn);
 static DEFINE_MUTEX(kgr_in_progress_lock);
 static LIST_HEAD(kgr_patches);
-static LIST_HEAD(kgr_to_revert);
 bool kgr_in_progress;
 static bool kgr_initialized;
 static struct kgr_patch *kgr_patch;
@@ -108,18 +107,6 @@ static void kgr_refs_dec(void)
 		p->refs--;
 }
 
-/* decrease reference for all older patches */
-static void kgr_refs_dec_limited(struct kgr_patch *limit)
-{
-	struct kgr_patch *p;
-
-	list_for_each_entry(p, &kgr_patches, list) {
-		if (p == limit)
-			return;
-		p->refs--;
-	}
-}
-
 static int kgr_ftrace_enable(struct kgr_patch_fun *pf, struct ftrace_ops *fops)
 {
 	int ret;
@@ -166,76 +153,85 @@ static bool kgr_still_patching(void)
 	return failed;
 }
 
-static bool kgr_patch_contains(const struct kgr_patch *p, const char *name)
-{
-	const struct kgr_patch_fun *pf;
-
-	kgr_for_each_patch_fun(p, pf)
-		if (!strcmp(pf->name, name))
-			return true;
-
-	return false;
-}
-
 /*
- * The patch is not longer used and can be removed immediately.
- * This function does the same as kgr_finalize() for reverted patches.
- * It just does not need to update the state of functions.
+ * The patches are no longer used and can be removed immediately, because
+ * replace_all patch is finalized (and not yet in the kgr_patches list). We do
+ * not have to deal with refs for older patches, since all of them are to be
+ * removed.
  */
-static void kgr_remove_patch_fast(struct kgr_patch *patch)
+static void kgr_remove_patches_fast(void)
 {
-	kgr_refs_dec_limited(patch);
-	list_del(&patch->list);
-	module_put(patch->owner);
+	struct kgr_patch *p, *tmp;
+
+	list_for_each_entry_safe(p, tmp, &kgr_patches, list) {
+		list_del(&p->list);
+		module_put(p->owner);
+	}
 }
 
 /*
- * All patches from kgr_patches are obsoleted and will get replaced
- * by kgr_patch.
+ * In case of replace_all patch we need to finalize also reverted functions in
+ * all previous patches. All previous patches contain only functions either in
+ * APPLIED state (not reverted and no longer used) or in REVERT_SLOW state. We
+ * mark the former as REVERTED and finalize the latter. Afterwards the patches
+ * can be safely removed from the patches list (by calling
+ * kgr_remove_patches_fast as in kgr_finalize).
  */
-static void kgr_replace_all(void)
+static void kgr_finalize_replaced_funs(void)
 {
 	struct kgr_patch_fun *pf;
-	struct kgr_patch *p, *tmp;
-
-	list_for_each_entry_safe(p, tmp, &kgr_patches, list) {
-		bool needs_revert = false;
+	struct kgr_patch *p;
+	int ret;
 
+	list_for_each_entry(p, &kgr_patches, list)
 		kgr_for_each_patch_fun(p, pf) {
-			if (pf->state != KGR_PATCH_APPLIED)
-				continue;
-
-			if (!kgr_patch_contains(kgr_patch, pf->name)) {
-				needs_revert = true;
+			/*
+			 * Function was not reverted, but is no longer used.
+			 * Mark it as reverted so the user would not be confused
+			 * by sysfs reporting of states.
+			 */
+			if (pf->state == KGR_PATCH_APPLIED) {
+				pf->state = KGR_PATCH_REVERTED;
 				continue;
 			}
 
-			/* the fast ftrace fops were disabled during patching */
-			pf->state = KGR_PATCH_REVERTED;
+			ret = kgr_patch_code(pf, true, true, true);
+			if (ret < 0)
+				pr_err("kgr: finalize for %s failed, trying to continue\n",
+				      pf->name);
 		}
-
-		if (needs_revert)
-			list_move(&p->list, &kgr_to_revert);
-		else
-			kgr_remove_patch_fast(p);
-	}
 }
 
 static void kgr_finalize(void)
 {
 	struct kgr_patch_fun *patch_fun;
-	struct kgr_patch *p_to_revert = NULL;
 
 	pr_info("kgr succeeded\n");
 
 	mutex_lock(&kgr_in_progress_lock);
 
 	kgr_for_each_patch_fun(kgr_patch, patch_fun) {
-		int ret = kgr_patch_code(patch_fun, true, kgr_revert);
+		int ret = kgr_patch_code(patch_fun, true, kgr_revert, false);
 
 		if (ret < 0)
 			pr_err("kgr: finalize for %s failed, trying to continue\n",
 					patch_fun->name);
+
+		/*
+		 * When applying the replace_all patch all older patches are
+		 * removed. We need to update loc_old and point it to the
+		 * original function for the patch_funs from replace_all patch.
+		 * The change is safe because the fast stub is used now. The
+		 * correct value might be needed later when the patch is
+		 * reverted.
+		 */
+		if (kgr_patch->replace_all && !kgr_revert)
+			patch_fun->loc_old = patch_fun->loc_name;
+	}
+
+	if (kgr_patch->replace_all && !kgr_revert) {
+		kgr_finalize_replaced_funs();
+		kgr_remove_patches_fast();
 	}
 
 	free_percpu(kgr_patch->irq_use_new);
@@ -244,31 +240,13 @@ static void kgr_finalize(void)
 		kgr_refs_dec();
 		module_put(kgr_patch->owner);
 	} else {
-		if (kgr_patch->replace_all)
-			kgr_replace_all();
 		list_add_tail(&kgr_patch->list, &kgr_patches);
 	}
 
 	kgr_patch = NULL;
-	if (list_empty(&kgr_to_revert)) {
-		kgr_in_progress = false;
-	} else {
-		/*
-		 * kgr_in_progress is not cleared to avoid races after the
-		 * unlock below. The force flag is set instead.
-		 */
-		p_to_revert = list_first_entry(&kgr_to_revert, struct kgr_patch,
-				list);
-	}
+	kgr_in_progress = false;
 
 	mutex_unlock(&kgr_in_progress_lock);
-
-	if (p_to_revert) {
-		int ret = kgr_modify_kernel(p_to_revert, true, true);
-		if (ret)
-			pr_err("kgr: continual revert of %s failedwith %d, but continuing\n",
-					p_to_revert->name, ret);
-	}
 }
 
 static void kgr_work_fn(struct work_struct *work)
@@ -546,7 +524,7 @@ static int kgr_init_ftrace_ops(struct kgr_patch_fun *patch_fun)
 }
 
 static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final,
-		bool revert)
+		bool revert, bool replace_revert)
 {
 	struct ftrace_ops *new_ops = NULL, *unreg_ops = NULL;
 	enum kgr_patch_state next_state;
@@ -554,7 +532,7 @@ static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final,
 
 	switch (patch_fun->state) {
 	case KGR_PATCH_INIT:
-		if (revert || final)
+		if (revert || final || replace_revert)
 			return -EINVAL;
 		err = kgr_init_ftrace_ops(patch_fun);
 		if (err) {
@@ -575,7 +553,7 @@ static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final,
 		unreg_ops = kgr_get_old_fops(patch_fun);
 		break;
 	case KGR_PATCH_SLOW:
-		if (revert || !final)
+		if (revert || !final || replace_revert)
 			return -EINVAL;
 		next_state = KGR_PATCH_APPLIED;
 		new_ops = &patch_fun->ftrace_ops_fast;
@@ -585,22 +563,37 @@ static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final,
 		if (!revert || final)
 			return -EINVAL;
 		next_state = KGR_PATCH_REVERT_SLOW;
-		new_ops = &patch_fun->ftrace_ops_slow;
-		unreg_ops = &patch_fun->ftrace_ops_fast;
+		/*
+		 * Update ftrace ops only when used. It is always needed for
+		 * normal revert and in case of replace_all patch for the last
+		 * patch_fun stacked (which has been as such called till now).
+		 */
+		if (!replace_revert ||
+		    kgr_is_patch_fun(patch_fun, KGR_LAST_FINALIZED)) {
+			new_ops = &patch_fun->ftrace_ops_slow;
+			unreg_ops = &patch_fun->ftrace_ops_fast;
+		}
 		break;
 	case KGR_PATCH_REVERT_SLOW:
 		if (!revert || !final)
 			return -EINVAL;
 		next_state = KGR_PATCH_REVERTED;
-		unreg_ops = &patch_fun->ftrace_ops_slow;
 		/*
-		 * Put back in place the old fops that were deregistered in
-		 * case of stacked patching (see the comment above).
+		 * Update ftrace only when used. Normal revert removes the slow
+		 * ops and enables fast ops from the fallback patch if any. In
+		 * case of replace_all patch and reverting old patch_funs we
+		 * just need to remove the slow stub and only for the last old
+		 * patch_fun. The original code will be used.
 		 */
-		new_ops = kgr_get_old_fops(patch_fun);
+		if (!replace_revert) {
+			unreg_ops = &patch_fun->ftrace_ops_slow;
+			new_ops = kgr_get_old_fops(patch_fun);
+		} else if (kgr_is_patch_fun(patch_fun, KGR_LAST_FINALIZED)) {
+			unreg_ops = &patch_fun->ftrace_ops_slow;
+		}
 		break;
 	case KGR_PATCH_REVERTED:
-		if (!revert || final)
+		if (!revert || final || replace_revert)
 			return -EINVAL;
 		return 0;
 	case KGR_PATCH_SKIPPED:
@@ -640,13 +633,63 @@ static int kgr_patch_code(struct kgr_patch_fun *patch_fun, bool final,
 	return 0;
 }
 
+static bool kgr_patch_contains(const struct kgr_patch *p, const char *name)
+{
+	const struct kgr_patch_fun *pf;
+
+	kgr_for_each_patch_fun(p, pf)
+		if (!strcmp(pf->name, name))
+			return true;
+
+	return false;
+}
+
+/*
+ * When replace_all patch is processed, all patches from kgr_patches are
+ * obsolete and will get replaced. All functions from the patches which are not
+ * patched in replace_all patch have to be reverted.
+ */
+static int kgr_revert_replaced_funs(struct kgr_patch *patch)
+{
+	struct kgr_patch *p;
+	struct kgr_patch_fun *pf;
+	int ret;
+
+	list_for_each_entry(p, &kgr_patches, list)
+		kgr_for_each_patch_fun(p, pf)
+			if (!kgr_patch_contains(patch, pf->name)) {
+				/*
+				 * Calls from new universe to all functions
+				 * being reverted are redirected to loc_old in
+				 * the slow stub. We need to call the original
+				 * functions and not the previous ones in terms
+				 * of stacking, so loc_old is changed to
+				 * loc_name.  Fast stub is still used, so change
+				 * of loc_old is safe.
+				 */
+				pf->loc_old = pf->loc_name;
+
+				ret = kgr_patch_code(pf, false, true, true);
+				if (ret < 0) {
+					/*
+					 * No need to fail with grace as in
+					 * kgr_modify_kernel
+					 */
+					pr_err("kgr: cannot revert function %s in patch %s\n",
+					      pf->name, p->name);
+					return ret;
+				}
+			}
+
+	return 0;
+}
+
 /**
  * kgr_modify_kernel -- apply or revert a patch
  * @patch: patch to deal with
  * @revert: if @patch should be reverted, set to true
- * @force: if kgr_in_progress should be ignored, set to true (internal use)
  */
-int kgr_modify_kernel(struct kgr_patch *patch, bool revert, bool force)
+int kgr_modify_kernel(struct kgr_patch *patch, bool revert)
 {
 	struct kgr_patch_fun *patch_fun;
 	int ret;
@@ -663,7 +706,7 @@ int kgr_modify_kernel(struct kgr_patch *patch, bool revert, bool force)
 		goto err_unlock;
 	}
 
-	if (!force && (kgr_in_progress || !list_empty(&kgr_to_revert))) {
+	if (kgr_in_progress) {
 		pr_err("kgr: can't patch, another patching not yet finalized\n");
 		ret = -EAGAIN;
 		goto err_unlock;
@@ -691,10 +734,20 @@ int kgr_modify_kernel(struct kgr_patch *patch, bool revert, bool force)
 		wmb(); /* set_bit before kgr_handle_processes */
 	}
 
+	/*
+	 * We need to revert patches of functions not patched in replace_all
+	 * patch. Do that only while applying the replace_all patch.
+	 */
+	if (patch->replace_all && !revert) {
+		ret = kgr_revert_replaced_funs(patch);
+		if (ret)
+			goto err_free;
+	}
+
 	kgr_for_each_patch_fun(patch, patch_fun) {
 		patch_fun->patch = patch;
 
-		ret = kgr_patch_code(patch_fun, false, revert);
+		ret = kgr_patch_code(patch_fun, false, revert, false);
 		/*
 		 * In case any of the symbol resolutions in the set
 		 * has failed, patch all the previously replaced fentry
@@ -763,7 +816,7 @@ int kgr_patch_kernel(struct kgr_patch *patch)
 	if (ret)
 		goto err_put;
 
-	ret = kgr_modify_kernel(patch, false, false);
+	ret = kgr_modify_kernel(patch, false);
 	if (ret)
 		goto err_dir_del;
 
@@ -802,6 +855,17 @@ EXPORT_SYMBOL_GPL(kgr_patch_remove);
  * use an old variant for the core functions. This is why we need to
  * use the slow stub when the patch is in progress. Both the core
  * kernel and module functions must be from the same universe.
+ *
+ * The situation differs a bit when the replace_all patch is being
+ * applied. The patch_funs present in the patch are pushed forward in
+ * the same way as for normal patches. So the slow stub is registered.
+ * The patch_funs not present in the replace_all patch have to be
+ * reverted. The slow stub is thus registered as well and next state
+ * set to KGR_PATCH_REVERT_SLOW. We can do it only for the last
+ * patch_funs in terms of stacking (KGR_LAST_FINALIZED), because the
+ * other would not be used at all and all older patches are going to
+ * be removed during finalization. Ftrace stub registration has to be
+ * done only for this last patch_fun.
  */
 static int kgr_patch_code_delayed(struct kgr_patch_fun *patch_fun)
 {
@@ -817,14 +881,23 @@ static int kgr_patch_code_delayed(struct kgr_patch_fun *patch_fun)
 		/* this must be the last existing patch on the stack */
 		new_ops = &patch_fun->ftrace_ops_slow;
 	} else {
-		next_state = KGR_PATCH_APPLIED;
-		/*
-		 * Check for the last existing and not the last finalized
-		 * patch_fun here! There might be another patch_fun in the
-		 * patch in progress that will be handled in the next calls.
-		 */
-		if (kgr_is_patch_fun(patch_fun, KGR_LAST_EXISTING))
-			new_ops = &patch_fun->ftrace_ops_fast;
+		if (kgr_patch && kgr_patch->replace_all && !kgr_revert &&
+		    !kgr_patch_contains(kgr_patch, patch_fun->name) &&
+		    kgr_is_patch_fun(patch_fun, KGR_LAST_FINALIZED)) {
+			next_state = KGR_PATCH_REVERT_SLOW;
+			patch_fun->loc_old = patch_fun->loc_name;
+			new_ops = &patch_fun->ftrace_ops_slow;
+		} else {
+			next_state = KGR_PATCH_APPLIED;
+			/*
+			 * Check for the last existing and not the last
+			 * finalized patch_fun here! There might be another
+			 * patch_fun in the patch in progress that will be
+			 * handled in the next calls.
+			 */
+			if (kgr_is_patch_fun(patch_fun, KGR_LAST_EXISTING))
+				new_ops = &patch_fun->ftrace_ops_fast;
+		}
 	}
 
 	if (new_ops) {
diff --git a/kernel/kgraft_files.c b/kernel/kgraft_files.c
index 0dff3da29b08..f6b4eae6b764 100644
--- a/kernel/kgraft_files.c
+++ b/kernel/kgraft_files.c
@@ -79,7 +79,7 @@ static ssize_t revert_store(struct kobject *kobj,
 	struct kgr_patch *p = kobj_to_patch(kobj);
 	int ret;
 
-	ret = kgr_modify_kernel(p, true, false);
+	ret = kgr_modify_kernel(p, true);
 
 	return ret < 0 ? ret : count;
 }
-- 
2.2.1

