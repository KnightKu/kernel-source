From a457cd7b93d14a6f14247123312457c0352dca71 Mon Sep 17 00:00:00 2001
From: Mel Gorman <mgorman@suse.de>
Date: Fri, 8 Jun 2012 15:32:54 +0100
Subject: [PATCH] mm: filemap: Optimise __lock_page_or_retry() by emulating an
 adaptive sleeping spinlock

References: VM performance, lock page scalability (bnc#436953, bnc#629170)
Patch-mainline: No (Never, no compelling use case other than boot times on very large machines)

Performance of lock_page on large machines can benefit if an acquirer
spins briefly waiting for the lock to be released if the page is uptodate
and not under writeback. A similar case applies when filemap_fault() is
faulting a read-only shared page.

Ordinarily during the first fault of a page an attempt is made to lock the
page and if that fails the mmap_sem is dropped and the fault retried. This
helps scalability of mmap_sem in many cases but not this particular
case.

This patch relieves the problem by having lock_page_or_retry() briefly
spin on UpToDate && !Writeback pages. If it gets the lock, great. If it
tries spinning and fails to get the lock it goes to full sleep on the lock
instead of retrying the full fault as it is expected the full fault would
contend a second time and just waste cycles.

Signed-off-by: Mel Gorman <mgorman@suse.de>
---
 mm/filemap.c | 61 ++++++++++++++++++++++++++++++++++++++++++++++++++++--------
 1 file changed, 53 insertions(+), 8 deletions(-)

diff --git a/mm/filemap.c b/mm/filemap.c
index 97de177..6e523a7 100644
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@ -670,6 +670,37 @@ void end_page_writeback(struct page *page)
 }
 EXPORT_SYMBOL(end_page_writeback);
 
+enum trylock_page_status {
+	TRYLOCK_PAGE_SUCCESS,
+	TRYLOCK_PAGE_FAILURE,
+	TRYLOCK_PAGE_SCHEDULE
+};
+
+/*
+ * If a page is locked, clean and uptodate then in many cases the hold time
+ * of the lock will be very short. It is better particularly on large machines
+ * to briefly spin instead of going to sleep on a waitqueue and dealing with
+ * the resulting wakestorm.
+ */
+static enum trylock_page_status spin_trylock_page(struct page *page)
+{
+	/*
+	 * Note that we do not spin for realtime tasks as a spinning realtime
+	 * realtime task could starve a non-rt holder of the page lock
+	 * resulting in a priority inversion.
+	 */
+	if (!PageUptodate(page) || PageWriteback(page) || rt_task(current))
+		return TRYLOCK_PAGE_FAILURE;
+
+	while (PageUptodate(page) && !PageWriteback(page) && !need_resched()) {
+		cpu_relax();
+		if (!PageLocked(page) && trylock_page(page))
+			return TRYLOCK_PAGE_SUCCESS;
+	}
+
+	return TRYLOCK_PAGE_SCHEDULE;
+}
+
 /**
  * __lock_page - get a lock on the page, assuming we need to sleep to get it
  * @page: the page to lock
@@ -680,14 +711,8 @@ void __lock_page(struct page *page)
 	DEFINE_WAIT_BIT(wait, &page->flags, PG_locked);
 
 	do {
-		if (!rt_task(current)) {
-			while (PageUptodate(page) && !PageWriteback(page) &&
-					!need_resched()) {
-				cpu_relax();
-				if (!PageLocked(page) && trylock_page(page))
-					goto done;
-			}
-		}
+		if (spin_trylock_page(page) == TRYLOCK_PAGE_SUCCESS)
+			goto done;
 
 		prepare_to_wait(wq, &wait.wait, TASK_UNINTERRUPTIBLE);
 		if (!PageWaiters(page))
@@ -707,6 +732,9 @@ int __lock_page_killable(struct page *page)
 	int err = 0;
 
 	do {
+		if (spin_trylock_page(page) == TRYLOCK_PAGE_SUCCESS)
+			goto done;
+
 		prepare_to_wait(wq, &wait.wait, TASK_KILLABLE);
 		if (!PageWaiters(page))
 			SetPageWaiters(page);
@@ -716,6 +744,7 @@ int __lock_page_killable(struct page *page)
 				break;
 		}
 	} while (!trylock_page(page));
+done:
 	finish_wait(wq, &wait.wait);
 
 	return err;
@@ -778,6 +807,21 @@ int __lock_page_or_retry(struct page *page, struct mm_struct *mm,
 		if (flags & FAULT_FLAG_RETRY_NOWAIT)
 			return 0;
 
+		/* Spin briefly if the hold time is likely to be short */
+		switch (spin_trylock_page(page)) {
+		case TRYLOCK_PAGE_SUCCESS:
+			return 1;
+		case TRYLOCK_PAGE_SCHEDULE:
+			/*
+			 * Spinned but still failed, fault retry will just
+			 * spin right round like a record so go to sleep
+			 */
+			goto force_lock;
+		case TRYLOCK_PAGE_FAILURE:
+			/* release mmap_sem and retry full fault */
+			;
+		}
+
 		up_read(&mm->mmap_sem);
 		if (flags & FAULT_FLAG_KILLABLE)
 			wait_on_page_locked_killable(page);
@@ -785,6 +829,7 @@ int __lock_page_or_retry(struct page *page, struct mm_struct *mm,
 			wait_on_page_locked(page);
 		return 0;
 	} else {
+force_lock:
 		if (flags & FAULT_FLAG_KILLABLE) {
 			int ret;
 
